{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (2.5.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (0.20.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (2.5.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (1.24.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (2.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: opencv-python in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\annay\\appdata\\roaming\\python\\python311\\site-packages (from opencv-python) (1.24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0+cu118\n",
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "Number of GPUs: 1\n",
      "GPU Name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import numpy as np\n",
    "from torchvision import models, transforms\n",
    "import cv2\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, data_file):\n",
    "        self.img_dir = img_dir\n",
    "        self.data = self._load_data(data_file)\n",
    "        self.transforms = self._build_transforms()\n",
    "\n",
    "    def _load_data(self, data_file):\n",
    "        with open(data_file, \"r\") as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    def _build_transforms(self):\n",
    "        return transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img = self._load_image(item[\"id\"])\n",
    "        img, kps = self._process_image_and_keypoints(img, item[\"kps\"])\n",
    "        return img, kps\n",
    "\n",
    "    def _load_image(self, img_id):\n",
    "        img_path = f\"{self.img_dir}/{img_id}.png\"\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        return img\n",
    "\n",
    "    def _process_image_and_keypoints(self, img, keypoints):\n",
    "        h, w = img.shape[:2]\n",
    "        img = self.transforms(img)\n",
    "        kps = np.array(keypoints, dtype=np.float32).flatten()\n",
    "        kps[::2] *= 224.0 / w \n",
    "        kps[1::2] *= 224.0 / h\n",
    "        return img, kps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = ImageDataset(img_dir=\"data/images\", data_file=\"data/data_train.json\")\n",
    "val_dataset = ImageDataset(img_dir=\"data/images\", data_file=\"data/data_val.json\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annay\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\annay\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc =  torch.nn.Linear(model.fc.in_features, 14*2)\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iter 0, loss: 14656.884765625\n",
      "Epoch 0, iter 10, loss: 14803.48828125\n",
      "Epoch 0, iter 20, loss: 13598.6103515625\n",
      "Epoch 0, iter 30, loss: 13789.7451171875\n",
      "Epoch 0, iter 40, loss: 13977.4873046875\n",
      "Epoch 0, iter 50, loss: 13054.314453125\n",
      "Epoch 0, iter 60, loss: 13312.2431640625\n",
      "Epoch 0, iter 70, loss: 12089.998046875\n",
      "Epoch 0, iter 80, loss: 11847.1279296875\n",
      "Epoch 0, iter 90, loss: 11584.8642578125\n",
      "Epoch 0, iter 100, loss: 11149.8818359375\n",
      "Epoch 0, iter 110, loss: 10382.1123046875\n",
      "Epoch 0, iter 120, loss: 10886.794921875\n",
      "Epoch 0, iter 130, loss: 10459.69140625\n",
      "Epoch 0, iter 140, loss: 9719.8505859375\n",
      "Epoch 0, iter 150, loss: 9796.7255859375\n",
      "Epoch 0, iter 160, loss: 9108.037109375\n",
      "Epoch 0, iter 170, loss: 8521.859375\n",
      "Epoch 0, iter 180, loss: 7707.30615234375\n",
      "Epoch 0, iter 190, loss: 8351.17578125\n",
      "Epoch 0, iter 200, loss: 7418.123046875\n",
      "Epoch 0, iter 210, loss: 7320.1533203125\n",
      "Epoch 0, iter 220, loss: 7943.533203125\n",
      "Epoch 0, iter 230, loss: 6699.02490234375\n",
      "Epoch 0, iter 240, loss: 6790.00634765625\n",
      "Epoch 0, iter 250, loss: 6544.37744140625\n",
      "Epoch 0, iter 260, loss: 6187.916015625\n",
      "Epoch 0, iter 270, loss: 6262.13330078125\n",
      "Epoch 0, iter 280, loss: 5569.98876953125\n",
      "Epoch 0, iter 290, loss: 5439.158203125\n",
      "Epoch 0, iter 300, loss: 5180.4052734375\n",
      "Epoch 0, iter 310, loss: 4792.5498046875\n",
      "Epoch 0, iter 320, loss: 4745.6162109375\n",
      "Epoch 0, iter 330, loss: 4367.611328125\n",
      "Epoch 0, iter 340, loss: 4395.390625\n",
      "Epoch 0, iter 350, loss: 4211.01806640625\n",
      "Epoch 0, iter 360, loss: 3987.44873046875\n",
      "Epoch 0, iter 370, loss: 3848.734619140625\n",
      "Epoch 0, iter 380, loss: 3393.02880859375\n",
      "Epoch 0, iter 390, loss: 3347.34619140625\n",
      "Epoch 0, iter 400, loss: 3112.8876953125\n",
      "Epoch 0, iter 410, loss: 2875.297119140625\n",
      "Epoch 0, iter 420, loss: 3181.66064453125\n",
      "Epoch 0, iter 430, loss: 2890.10595703125\n",
      "Epoch 0, iter 440, loss: 2746.017333984375\n",
      "Epoch 0, iter 450, loss: 2570.879638671875\n",
      "Epoch 0, iter 460, loss: 2412.384033203125\n",
      "Epoch 0, iter 470, loss: 2396.150390625\n",
      "Epoch 0, iter 480, loss: 2109.83349609375\n",
      "Epoch 0, iter 490, loss: 1975.5355224609375\n",
      "Epoch 0, iter 500, loss: 1722.6043701171875\n",
      "Epoch 0, iter 510, loss: 2091.9443359375\n",
      "Epoch 0, iter 520, loss: 1877.323486328125\n",
      "Epoch 0, iter 530, loss: 1622.5982666015625\n",
      "Epoch 0, iter 540, loss: 1522.315673828125\n",
      "Epoch 0, iter 550, loss: 1474.3482666015625\n",
      "Epoch 0, iter 560, loss: 1389.61474609375\n",
      "Epoch 0, iter 570, loss: 1293.71337890625\n",
      "Epoch 0, iter 580, loss: 1171.038330078125\n",
      "Epoch 0, iter 590, loss: 1154.1146240234375\n",
      "Epoch 0, iter 600, loss: 1180.5142822265625\n",
      "Epoch 0, iter 610, loss: 892.55126953125\n",
      "Epoch 0, iter 620, loss: 945.9679565429688\n",
      "Epoch 0, iter 630, loss: 1025.1314697265625\n",
      "Epoch 0, iter 640, loss: 771.1610107421875\n",
      "Epoch 0, iter 650, loss: 686.3076782226562\n",
      "Epoch 0, iter 660, loss: 791.193115234375\n",
      "Epoch 0, iter 670, loss: 601.1718139648438\n",
      "Epoch 0, iter 680, loss: 515.6925048828125\n",
      "Epoch 0, iter 690, loss: 847.6203002929688\n",
      "Epoch 0, iter 700, loss: 731.1094360351562\n",
      "Epoch 0, iter 710, loss: 546.844482421875\n",
      "Epoch 0, iter 720, loss: 534.9708862304688\n",
      "Epoch 0, iter 730, loss: 624.1806640625\n",
      "Epoch 0, iter 740, loss: 399.3542175292969\n",
      "Epoch 0, iter 750, loss: 481.94091796875\n",
      "Epoch 0, iter 760, loss: 322.42340087890625\n",
      "Epoch 0, iter 770, loss: 410.4630126953125\n",
      "Epoch 0, iter 780, loss: 365.77679443359375\n",
      "Epoch 0, iter 790, loss: 335.5921630859375\n",
      "Epoch 0, iter 800, loss: 269.72601318359375\n",
      "Epoch 0, iter 810, loss: 353.4961242675781\n",
      "Epoch 0, iter 820, loss: 226.6389923095703\n",
      "Model saved after epoch 1\n",
      "Epoch 1, iter 0, loss: 256.91595458984375\n",
      "Epoch 1, iter 10, loss: 415.3675842285156\n",
      "Epoch 1, iter 20, loss: 172.6460723876953\n",
      "Epoch 1, iter 30, loss: 261.6419982910156\n",
      "Epoch 1, iter 40, loss: 216.51068115234375\n",
      "Epoch 1, iter 50, loss: 181.59898376464844\n",
      "Epoch 1, iter 60, loss: 133.6741943359375\n",
      "Epoch 1, iter 70, loss: 152.67965698242188\n",
      "Epoch 1, iter 80, loss: 242.4950408935547\n",
      "Epoch 1, iter 90, loss: 128.283447265625\n",
      "Epoch 1, iter 100, loss: 118.92832946777344\n",
      "Epoch 1, iter 110, loss: 148.94908142089844\n",
      "Epoch 1, iter 120, loss: 84.33340454101562\n",
      "Epoch 1, iter 130, loss: 135.85708618164062\n",
      "Epoch 1, iter 140, loss: 124.0571060180664\n",
      "Epoch 1, iter 150, loss: 89.52436828613281\n",
      "Epoch 1, iter 160, loss: 82.05073547363281\n",
      "Epoch 1, iter 170, loss: 78.53691101074219\n",
      "Epoch 1, iter 180, loss: 145.1866455078125\n",
      "Epoch 1, iter 190, loss: 128.10865783691406\n",
      "Epoch 1, iter 200, loss: 65.59758758544922\n",
      "Epoch 1, iter 210, loss: 74.23252868652344\n",
      "Epoch 1, iter 220, loss: 150.1773681640625\n",
      "Epoch 1, iter 230, loss: 56.95538330078125\n",
      "Epoch 1, iter 240, loss: 87.07862854003906\n",
      "Epoch 1, iter 250, loss: 87.8640365600586\n",
      "Epoch 1, iter 260, loss: 158.09384155273438\n",
      "Epoch 1, iter 270, loss: 78.92625427246094\n",
      "Epoch 1, iter 280, loss: 73.6559829711914\n",
      "Epoch 1, iter 290, loss: 55.73194885253906\n",
      "Epoch 1, iter 300, loss: 46.83516311645508\n",
      "Epoch 1, iter 310, loss: 98.47341918945312\n",
      "Epoch 1, iter 320, loss: 40.73798751831055\n",
      "Epoch 1, iter 330, loss: 115.42218780517578\n",
      "Epoch 1, iter 340, loss: 30.309358596801758\n",
      "Epoch 1, iter 350, loss: 89.22770690917969\n",
      "Epoch 1, iter 360, loss: 50.90626907348633\n",
      "Epoch 1, iter 370, loss: 35.17289352416992\n",
      "Epoch 1, iter 380, loss: 52.70628356933594\n",
      "Epoch 1, iter 390, loss: 28.449172973632812\n",
      "Epoch 1, iter 400, loss: 67.40516662597656\n",
      "Epoch 1, iter 410, loss: 51.1733512878418\n",
      "Epoch 1, iter 420, loss: 92.93169403076172\n",
      "Epoch 1, iter 430, loss: 51.94477844238281\n",
      "Epoch 1, iter 440, loss: 41.1065788269043\n",
      "Epoch 1, iter 450, loss: 20.344810485839844\n",
      "Epoch 1, iter 460, loss: 28.8004093170166\n",
      "Epoch 1, iter 470, loss: 39.21129608154297\n",
      "Epoch 1, iter 480, loss: 133.1587677001953\n",
      "Epoch 1, iter 490, loss: 67.33259582519531\n",
      "Epoch 1, iter 500, loss: 33.7802848815918\n",
      "Epoch 1, iter 510, loss: 36.80731964111328\n",
      "Epoch 1, iter 520, loss: 93.36072540283203\n",
      "Epoch 1, iter 530, loss: 37.730690002441406\n",
      "Epoch 1, iter 540, loss: 19.437061309814453\n",
      "Epoch 1, iter 550, loss: 42.10725784301758\n",
      "Epoch 1, iter 560, loss: 68.49655151367188\n",
      "Epoch 1, iter 570, loss: 55.613590240478516\n",
      "Epoch 1, iter 580, loss: 100.64322662353516\n",
      "Epoch 1, iter 590, loss: 14.1914701461792\n",
      "Epoch 1, iter 600, loss: 26.95212173461914\n",
      "Epoch 1, iter 610, loss: 39.05430221557617\n",
      "Epoch 1, iter 620, loss: 43.932472229003906\n",
      "Epoch 1, iter 630, loss: 34.38318634033203\n",
      "Epoch 1, iter 640, loss: 61.53059005737305\n",
      "Epoch 1, iter 650, loss: 44.78232955932617\n",
      "Epoch 1, iter 660, loss: 31.889949798583984\n",
      "Epoch 1, iter 670, loss: 38.1572265625\n",
      "Epoch 1, iter 680, loss: 60.436561584472656\n",
      "Epoch 1, iter 690, loss: 189.34808349609375\n",
      "Epoch 1, iter 700, loss: 20.775497436523438\n",
      "Epoch 1, iter 710, loss: 24.11097526550293\n",
      "Epoch 1, iter 720, loss: 24.71744155883789\n",
      "Epoch 1, iter 730, loss: 27.792381286621094\n",
      "Epoch 1, iter 740, loss: 26.5201473236084\n",
      "Epoch 1, iter 750, loss: 40.56890869140625\n",
      "Epoch 1, iter 760, loss: 23.762874603271484\n",
      "Epoch 1, iter 770, loss: 26.208248138427734\n",
      "Epoch 1, iter 780, loss: 19.632183074951172\n",
      "Epoch 1, iter 790, loss: 42.625030517578125\n",
      "Epoch 1, iter 800, loss: 69.73567199707031\n",
      "Epoch 1, iter 810, loss: 26.906002044677734\n",
      "Epoch 1, iter 820, loss: 105.6937484741211\n",
      "Model saved after epoch 2\n",
      "Epoch 2, iter 0, loss: 32.899391174316406\n",
      "Epoch 2, iter 10, loss: 40.54517364501953\n",
      "Epoch 2, iter 20, loss: 56.37053680419922\n",
      "Epoch 2, iter 30, loss: 33.00344467163086\n",
      "Epoch 2, iter 40, loss: 41.083251953125\n",
      "Epoch 2, iter 50, loss: 49.2888298034668\n",
      "Epoch 2, iter 60, loss: 30.6160945892334\n",
      "Epoch 2, iter 70, loss: 46.862735748291016\n",
      "Epoch 2, iter 80, loss: 17.64896011352539\n",
      "Epoch 2, iter 90, loss: 30.083253860473633\n",
      "Epoch 2, iter 100, loss: 31.86742401123047\n",
      "Epoch 2, iter 110, loss: 47.424129486083984\n",
      "Epoch 2, iter 120, loss: 29.766759872436523\n",
      "Epoch 2, iter 130, loss: 21.556921005249023\n",
      "Epoch 2, iter 140, loss: 75.6543197631836\n",
      "Epoch 2, iter 150, loss: 54.012203216552734\n",
      "Epoch 2, iter 160, loss: 65.84923553466797\n",
      "Epoch 2, iter 170, loss: 26.522035598754883\n",
      "Epoch 2, iter 180, loss: 20.632953643798828\n",
      "Epoch 2, iter 190, loss: 31.55887794494629\n",
      "Epoch 2, iter 200, loss: 77.56941986083984\n",
      "Epoch 2, iter 210, loss: 169.3264923095703\n",
      "Epoch 2, iter 220, loss: 32.56916809082031\n",
      "Epoch 2, iter 230, loss: 30.08339500427246\n",
      "Epoch 2, iter 240, loss: 20.31201171875\n",
      "Epoch 2, iter 250, loss: 38.3232421875\n",
      "Epoch 2, iter 260, loss: 28.886775970458984\n",
      "Epoch 2, iter 270, loss: 19.026954650878906\n",
      "Epoch 2, iter 280, loss: 46.21150588989258\n",
      "Epoch 2, iter 290, loss: 24.768733978271484\n",
      "Epoch 2, iter 300, loss: 26.10921859741211\n",
      "Epoch 2, iter 310, loss: 19.595050811767578\n",
      "Epoch 2, iter 320, loss: 16.252933502197266\n",
      "Epoch 2, iter 330, loss: 42.60187911987305\n",
      "Epoch 2, iter 340, loss: 51.671531677246094\n",
      "Epoch 2, iter 350, loss: 16.93618392944336\n",
      "Epoch 2, iter 360, loss: 15.598440170288086\n",
      "Epoch 2, iter 370, loss: 18.190689086914062\n",
      "Epoch 2, iter 380, loss: 165.1250457763672\n",
      "Epoch 2, iter 390, loss: 33.43606948852539\n",
      "Epoch 2, iter 400, loss: 82.2735824584961\n",
      "Epoch 2, iter 410, loss: 19.859962463378906\n",
      "Epoch 2, iter 420, loss: 72.9998779296875\n",
      "Epoch 2, iter 430, loss: 137.31544494628906\n",
      "Epoch 2, iter 440, loss: 75.52963256835938\n",
      "Epoch 2, iter 450, loss: 18.567611694335938\n",
      "Epoch 2, iter 460, loss: 20.768476486206055\n",
      "Epoch 2, iter 470, loss: 18.334142684936523\n",
      "Epoch 2, iter 480, loss: 41.40589904785156\n",
      "Epoch 2, iter 490, loss: 27.693538665771484\n",
      "Epoch 2, iter 500, loss: 21.879304885864258\n",
      "Epoch 2, iter 510, loss: 24.053646087646484\n",
      "Epoch 2, iter 520, loss: 38.61006546020508\n",
      "Epoch 2, iter 530, loss: 29.806100845336914\n",
      "Epoch 2, iter 540, loss: 24.440092086791992\n",
      "Epoch 2, iter 550, loss: 32.068050384521484\n",
      "Epoch 2, iter 560, loss: 13.285503387451172\n",
      "Epoch 2, iter 570, loss: 19.531021118164062\n",
      "Epoch 2, iter 580, loss: 22.758283615112305\n",
      "Epoch 2, iter 590, loss: 32.50730895996094\n",
      "Epoch 2, iter 600, loss: 26.655643463134766\n",
      "Epoch 2, iter 610, loss: 20.53813934326172\n",
      "Epoch 2, iter 620, loss: 15.110244750976562\n",
      "Epoch 2, iter 630, loss: 32.1756706237793\n",
      "Epoch 2, iter 640, loss: 23.25160026550293\n",
      "Epoch 2, iter 650, loss: 11.018219947814941\n",
      "Epoch 2, iter 660, loss: 158.63851928710938\n",
      "Epoch 2, iter 670, loss: 52.8833122253418\n",
      "Epoch 2, iter 680, loss: 17.797582626342773\n",
      "Epoch 2, iter 690, loss: 28.553579330444336\n",
      "Epoch 2, iter 700, loss: 53.65972137451172\n",
      "Epoch 2, iter 710, loss: 35.7358512878418\n",
      "Epoch 2, iter 720, loss: 37.260223388671875\n",
      "Epoch 2, iter 730, loss: 19.581504821777344\n",
      "Epoch 2, iter 740, loss: 33.22227096557617\n",
      "Epoch 2, iter 750, loss: 32.4088249206543\n",
      "Epoch 2, iter 760, loss: 18.287153244018555\n",
      "Epoch 2, iter 770, loss: 31.120824813842773\n",
      "Epoch 2, iter 780, loss: 24.7214412689209\n",
      "Epoch 2, iter 790, loss: 34.50141143798828\n",
      "Epoch 2, iter 800, loss: 53.102352142333984\n",
      "Epoch 2, iter 810, loss: 24.260961532592773\n",
      "Epoch 2, iter 820, loss: 31.634973526000977\n",
      "Model saved after epoch 3\n",
      "Epoch 3, iter 0, loss: 28.469667434692383\n",
      "Epoch 3, iter 10, loss: 43.780372619628906\n",
      "Epoch 3, iter 20, loss: 28.537633895874023\n",
      "Epoch 3, iter 30, loss: 32.5008659362793\n",
      "Epoch 3, iter 40, loss: 26.633825302124023\n",
      "Epoch 3, iter 50, loss: 15.550836563110352\n",
      "Epoch 3, iter 60, loss: 16.989423751831055\n",
      "Epoch 3, iter 70, loss: 38.64317321777344\n",
      "Epoch 3, iter 80, loss: 24.752887725830078\n",
      "Epoch 3, iter 90, loss: 22.829591751098633\n",
      "Epoch 3, iter 100, loss: 24.356271743774414\n",
      "Epoch 3, iter 110, loss: 31.261863708496094\n",
      "Epoch 3, iter 120, loss: 33.366878509521484\n",
      "Epoch 3, iter 130, loss: 60.558692932128906\n",
      "Epoch 3, iter 140, loss: 183.3192596435547\n",
      "Epoch 3, iter 150, loss: 33.32561492919922\n",
      "Epoch 3, iter 160, loss: 18.04438018798828\n",
      "Epoch 3, iter 170, loss: 23.992229461669922\n",
      "Epoch 3, iter 180, loss: 34.44440841674805\n",
      "Epoch 3, iter 190, loss: 18.516210556030273\n",
      "Epoch 3, iter 200, loss: 13.359622955322266\n",
      "Epoch 3, iter 210, loss: 14.144211769104004\n",
      "Epoch 3, iter 220, loss: 13.678685188293457\n",
      "Epoch 3, iter 230, loss: 15.171075820922852\n",
      "Epoch 3, iter 240, loss: 10.656267166137695\n",
      "Epoch 3, iter 250, loss: 42.78984832763672\n",
      "Epoch 3, iter 260, loss: 11.998943328857422\n",
      "Epoch 3, iter 270, loss: 17.268064498901367\n",
      "Epoch 3, iter 280, loss: 31.072763442993164\n",
      "Epoch 3, iter 290, loss: 16.848411560058594\n",
      "Epoch 3, iter 300, loss: 17.87277603149414\n",
      "Epoch 3, iter 310, loss: 19.790708541870117\n",
      "Epoch 3, iter 320, loss: 18.26304054260254\n",
      "Epoch 3, iter 330, loss: 20.89358901977539\n",
      "Epoch 3, iter 340, loss: 18.739627838134766\n",
      "Epoch 3, iter 350, loss: 14.167208671569824\n",
      "Epoch 3, iter 360, loss: 31.7418270111084\n",
      "Epoch 3, iter 370, loss: 18.76814842224121\n",
      "Epoch 3, iter 380, loss: 22.19233512878418\n",
      "Epoch 3, iter 390, loss: 34.46324157714844\n",
      "Epoch 3, iter 400, loss: 14.929858207702637\n",
      "Epoch 3, iter 410, loss: 24.359657287597656\n",
      "Epoch 3, iter 420, loss: 68.74082946777344\n",
      "Epoch 3, iter 430, loss: 16.917633056640625\n",
      "Epoch 3, iter 440, loss: 13.259862899780273\n",
      "Epoch 3, iter 450, loss: 54.89540100097656\n",
      "Epoch 3, iter 460, loss: 56.99388122558594\n",
      "Epoch 3, iter 470, loss: 20.563533782958984\n",
      "Epoch 3, iter 480, loss: 11.41246223449707\n",
      "Epoch 3, iter 490, loss: 21.992162704467773\n",
      "Epoch 3, iter 500, loss: 10.193076133728027\n",
      "Epoch 3, iter 510, loss: 15.000088691711426\n",
      "Epoch 3, iter 520, loss: 10.672491073608398\n",
      "Epoch 3, iter 530, loss: 10.240718841552734\n",
      "Epoch 3, iter 540, loss: 15.370418548583984\n",
      "Epoch 3, iter 550, loss: 11.766569137573242\n",
      "Epoch 3, iter 560, loss: 56.677345275878906\n",
      "Epoch 3, iter 570, loss: 14.650218963623047\n",
      "Epoch 3, iter 580, loss: 12.011977195739746\n",
      "Epoch 3, iter 590, loss: 26.497303009033203\n",
      "Epoch 3, iter 600, loss: 32.72636413574219\n",
      "Epoch 3, iter 610, loss: 53.88127136230469\n",
      "Epoch 3, iter 620, loss: 24.989931106567383\n",
      "Epoch 3, iter 630, loss: 23.666034698486328\n",
      "Epoch 3, iter 640, loss: 7.674070358276367\n",
      "Epoch 3, iter 650, loss: 9.326449394226074\n",
      "Epoch 3, iter 660, loss: 11.687511444091797\n",
      "Epoch 3, iter 670, loss: 15.911805152893066\n",
      "Epoch 3, iter 680, loss: 13.611313819885254\n",
      "Epoch 3, iter 690, loss: 8.54167366027832\n",
      "Epoch 3, iter 700, loss: 19.3178768157959\n",
      "Epoch 3, iter 710, loss: 23.157148361206055\n",
      "Epoch 3, iter 720, loss: 8.587440490722656\n",
      "Epoch 3, iter 730, loss: 9.89978313446045\n",
      "Epoch 3, iter 740, loss: 22.71772575378418\n",
      "Epoch 3, iter 750, loss: 28.887887954711914\n",
      "Epoch 3, iter 760, loss: 14.531963348388672\n",
      "Epoch 3, iter 770, loss: 28.59349822998047\n",
      "Epoch 3, iter 780, loss: 12.119241714477539\n",
      "Epoch 3, iter 790, loss: 93.51375579833984\n",
      "Epoch 3, iter 800, loss: 19.19843864440918\n",
      "Epoch 3, iter 810, loss: 19.24785614013672\n",
      "Epoch 3, iter 820, loss: 27.244794845581055\n",
      "Model saved after epoch 4\n",
      "Epoch 4, iter 0, loss: 14.983152389526367\n",
      "Epoch 4, iter 10, loss: 20.983285903930664\n",
      "Epoch 4, iter 20, loss: 33.35589599609375\n",
      "Epoch 4, iter 30, loss: 110.36085510253906\n",
      "Epoch 4, iter 40, loss: 15.445322036743164\n",
      "Epoch 4, iter 50, loss: 12.483241081237793\n",
      "Epoch 4, iter 60, loss: 12.800400733947754\n",
      "Epoch 4, iter 70, loss: 18.16950225830078\n",
      "Epoch 4, iter 80, loss: 58.23499298095703\n",
      "Epoch 4, iter 90, loss: 8.979552268981934\n",
      "Epoch 4, iter 100, loss: 37.11336898803711\n",
      "Epoch 4, iter 110, loss: 43.445777893066406\n",
      "Epoch 4, iter 120, loss: 11.4465970993042\n",
      "Epoch 4, iter 130, loss: 5.938553333282471\n",
      "Epoch 4, iter 140, loss: 19.812580108642578\n",
      "Epoch 4, iter 150, loss: 11.231810569763184\n",
      "Epoch 4, iter 160, loss: 51.915016174316406\n",
      "Epoch 4, iter 170, loss: 16.272024154663086\n",
      "Epoch 4, iter 180, loss: 48.236061096191406\n",
      "Epoch 4, iter 190, loss: 8.384611129760742\n",
      "Epoch 4, iter 200, loss: 8.80661678314209\n",
      "Epoch 4, iter 210, loss: 3.7727603912353516\n",
      "Epoch 4, iter 220, loss: 44.573707580566406\n",
      "Epoch 4, iter 230, loss: 25.753267288208008\n",
      "Epoch 4, iter 240, loss: 7.979819297790527\n",
      "Epoch 4, iter 250, loss: 9.961210250854492\n",
      "Epoch 4, iter 260, loss: 13.53775405883789\n",
      "Epoch 4, iter 270, loss: 9.358049392700195\n",
      "Epoch 4, iter 280, loss: 8.860487937927246\n",
      "Epoch 4, iter 290, loss: 26.28770637512207\n",
      "Epoch 4, iter 300, loss: 5.851319313049316\n",
      "Epoch 4, iter 310, loss: 6.503856182098389\n",
      "Epoch 4, iter 320, loss: 43.29084396362305\n",
      "Epoch 4, iter 330, loss: 8.110567092895508\n",
      "Epoch 4, iter 340, loss: 12.2553071975708\n",
      "Epoch 4, iter 350, loss: 6.378857612609863\n",
      "Epoch 4, iter 360, loss: 8.265218734741211\n",
      "Epoch 4, iter 370, loss: 17.435922622680664\n",
      "Epoch 4, iter 380, loss: 17.29466438293457\n",
      "Epoch 4, iter 390, loss: 7.875879764556885\n",
      "Epoch 4, iter 400, loss: 12.119504928588867\n",
      "Epoch 4, iter 410, loss: 23.6295108795166\n",
      "Epoch 4, iter 420, loss: 6.406942367553711\n",
      "Epoch 4, iter 430, loss: 13.5897855758667\n",
      "Epoch 4, iter 440, loss: 9.212185859680176\n",
      "Epoch 4, iter 450, loss: 7.918480396270752\n",
      "Epoch 4, iter 460, loss: 6.814845561981201\n",
      "Epoch 4, iter 470, loss: 53.443111419677734\n",
      "Epoch 4, iter 480, loss: 17.648601531982422\n",
      "Epoch 4, iter 490, loss: 11.084565162658691\n",
      "Epoch 4, iter 500, loss: 22.963306427001953\n",
      "Epoch 4, iter 510, loss: 3.7904903888702393\n",
      "Epoch 4, iter 520, loss: 6.805690288543701\n",
      "Epoch 4, iter 530, loss: 11.747801780700684\n",
      "Epoch 4, iter 540, loss: 6.375810623168945\n",
      "Epoch 4, iter 550, loss: 66.3680648803711\n",
      "Epoch 4, iter 560, loss: 15.479281425476074\n",
      "Epoch 4, iter 570, loss: 4.727869033813477\n",
      "Epoch 4, iter 580, loss: 6.234842777252197\n",
      "Epoch 4, iter 590, loss: 4.535915374755859\n",
      "Epoch 4, iter 600, loss: 20.996057510375977\n",
      "Epoch 4, iter 610, loss: 11.610864639282227\n",
      "Epoch 4, iter 620, loss: 15.922910690307617\n",
      "Epoch 4, iter 630, loss: 3.6777448654174805\n",
      "Epoch 4, iter 640, loss: 11.829801559448242\n",
      "Epoch 4, iter 650, loss: 12.94882869720459\n",
      "Epoch 4, iter 660, loss: 5.945537090301514\n",
      "Epoch 4, iter 670, loss: 7.462851524353027\n",
      "Epoch 4, iter 680, loss: 40.862266540527344\n",
      "Epoch 4, iter 690, loss: 5.5080790519714355\n",
      "Epoch 4, iter 700, loss: 7.547495365142822\n",
      "Epoch 4, iter 710, loss: 14.80186939239502\n",
      "Epoch 4, iter 720, loss: 16.596027374267578\n",
      "Epoch 4, iter 730, loss: 7.725530624389648\n",
      "Epoch 4, iter 740, loss: 7.180117130279541\n",
      "Epoch 4, iter 750, loss: 4.695338726043701\n",
      "Epoch 4, iter 760, loss: 16.211305618286133\n",
      "Epoch 4, iter 770, loss: 5.215325355529785\n",
      "Epoch 4, iter 780, loss: 5.183504581451416\n",
      "Epoch 4, iter 790, loss: 6.155762195587158\n",
      "Epoch 4, iter 800, loss: 5.769498825073242\n",
      "Epoch 4, iter 810, loss: 10.449912071228027\n",
      "Epoch 4, iter 820, loss: 4.79238748550415\n",
      "Model saved after epoch 5\n",
      "Epoch 5, iter 0, loss: 23.19188690185547\n",
      "Epoch 5, iter 10, loss: 7.051913261413574\n",
      "Epoch 5, iter 20, loss: 11.450479507446289\n",
      "Epoch 5, iter 30, loss: 11.370184898376465\n",
      "Epoch 5, iter 40, loss: 21.538108825683594\n",
      "Epoch 5, iter 50, loss: 12.792936325073242\n",
      "Epoch 5, iter 60, loss: 6.352669715881348\n",
      "Epoch 5, iter 70, loss: 9.757834434509277\n",
      "Epoch 5, iter 80, loss: 6.06906270980835\n",
      "Epoch 5, iter 90, loss: 12.118925094604492\n",
      "Epoch 5, iter 100, loss: 3.3402504920959473\n",
      "Epoch 5, iter 110, loss: 8.29517936706543\n",
      "Epoch 5, iter 120, loss: 4.476011276245117\n",
      "Epoch 5, iter 130, loss: 3.2372477054595947\n",
      "Epoch 5, iter 140, loss: 5.352035045623779\n",
      "Epoch 5, iter 150, loss: 7.124814987182617\n",
      "Epoch 5, iter 160, loss: 30.379901885986328\n",
      "Epoch 5, iter 170, loss: 17.313488006591797\n",
      "Epoch 5, iter 180, loss: 6.407449245452881\n",
      "Epoch 5, iter 190, loss: 20.768421173095703\n",
      "Epoch 5, iter 200, loss: 6.732010364532471\n",
      "Epoch 5, iter 210, loss: 393.20953369140625\n",
      "Epoch 5, iter 220, loss: 12.426472663879395\n",
      "Epoch 5, iter 230, loss: 7.445448875427246\n",
      "Epoch 5, iter 240, loss: 24.40522575378418\n",
      "Epoch 5, iter 250, loss: 7.342878818511963\n",
      "Epoch 5, iter 260, loss: 5.881705284118652\n",
      "Epoch 5, iter 270, loss: 6.6581711769104\n",
      "Epoch 5, iter 280, loss: 7.093706130981445\n",
      "Epoch 5, iter 290, loss: 8.239034652709961\n",
      "Epoch 5, iter 300, loss: 6.020213603973389\n",
      "Epoch 5, iter 310, loss: 18.387386322021484\n",
      "Epoch 5, iter 320, loss: 4.633632183074951\n",
      "Epoch 5, iter 330, loss: 6.544720649719238\n",
      "Epoch 5, iter 340, loss: 1.8207591772079468\n",
      "Epoch 5, iter 350, loss: 9.70129680633545\n",
      "Epoch 5, iter 360, loss: 5.840581893920898\n",
      "Epoch 5, iter 370, loss: 11.18303394317627\n",
      "Epoch 5, iter 380, loss: 6.047214031219482\n",
      "Epoch 5, iter 390, loss: 8.11066722869873\n",
      "Epoch 5, iter 400, loss: 7.438222885131836\n",
      "Epoch 5, iter 410, loss: 66.49016571044922\n",
      "Epoch 5, iter 420, loss: 7.147579193115234\n",
      "Epoch 5, iter 430, loss: 3.921992778778076\n",
      "Epoch 5, iter 440, loss: 5.719283103942871\n",
      "Epoch 5, iter 450, loss: 13.62883186340332\n",
      "Epoch 5, iter 460, loss: 2.5841262340545654\n",
      "Epoch 5, iter 470, loss: 2.2759196758270264\n",
      "Epoch 5, iter 480, loss: 82.113037109375\n",
      "Epoch 5, iter 490, loss: 6.994941711425781\n",
      "Epoch 5, iter 500, loss: 1.7285118103027344\n",
      "Epoch 5, iter 510, loss: 6.046319961547852\n",
      "Epoch 5, iter 520, loss: 170.394287109375\n",
      "Epoch 5, iter 530, loss: 3.0730509757995605\n",
      "Epoch 5, iter 540, loss: 3.1476571559906006\n",
      "Epoch 5, iter 550, loss: 2.583958387374878\n",
      "Epoch 5, iter 560, loss: 5.351974010467529\n",
      "Epoch 5, iter 570, loss: 4.767805099487305\n",
      "Epoch 5, iter 580, loss: 8.490367889404297\n",
      "Epoch 5, iter 590, loss: 15.883442878723145\n",
      "Epoch 5, iter 600, loss: 5.2739715576171875\n",
      "Epoch 5, iter 610, loss: 19.748584747314453\n",
      "Epoch 5, iter 620, loss: 3.4680237770080566\n",
      "Epoch 5, iter 630, loss: 4.992610454559326\n",
      "Epoch 5, iter 640, loss: 5.103515625\n",
      "Epoch 5, iter 650, loss: 3.3578667640686035\n",
      "Epoch 5, iter 660, loss: 6.567352771759033\n",
      "Epoch 5, iter 670, loss: 4.857939720153809\n",
      "Epoch 5, iter 680, loss: 11.880624771118164\n",
      "Epoch 5, iter 690, loss: 384.9573059082031\n",
      "Epoch 5, iter 700, loss: 12.56533432006836\n",
      "Epoch 5, iter 710, loss: 8.616026878356934\n",
      "Epoch 5, iter 720, loss: 16.707990646362305\n",
      "Epoch 5, iter 730, loss: 11.61495590209961\n",
      "Epoch 5, iter 740, loss: 5.374626636505127\n",
      "Epoch 5, iter 750, loss: 5.437840461730957\n",
      "Epoch 5, iter 760, loss: 17.185407638549805\n",
      "Epoch 5, iter 770, loss: 7.164677619934082\n",
      "Epoch 5, iter 780, loss: 1.9122804403305054\n",
      "Epoch 5, iter 790, loss: 3.7383015155792236\n",
      "Epoch 5, iter 800, loss: 32.208431243896484\n",
      "Epoch 5, iter 810, loss: 10.785174369812012\n",
      "Epoch 5, iter 820, loss: 5.923976421356201\n",
      "Model saved after epoch 6\n",
      "Epoch 6, iter 0, loss: 10.64695930480957\n",
      "Epoch 6, iter 10, loss: 6.86961555480957\n",
      "Epoch 6, iter 20, loss: 25.2221736907959\n",
      "Epoch 6, iter 30, loss: 14.451142311096191\n",
      "Epoch 6, iter 40, loss: 23.765316009521484\n",
      "Epoch 6, iter 50, loss: 8.512235641479492\n",
      "Epoch 6, iter 60, loss: 8.334003448486328\n",
      "Epoch 6, iter 70, loss: 33.76198959350586\n",
      "Epoch 6, iter 80, loss: 4.6931657791137695\n",
      "Epoch 6, iter 90, loss: 13.232946395874023\n",
      "Epoch 6, iter 100, loss: 3.6055667400360107\n",
      "Epoch 6, iter 110, loss: 1.0304179191589355\n",
      "Epoch 6, iter 120, loss: 15.796448707580566\n",
      "Epoch 6, iter 130, loss: 141.07025146484375\n",
      "Epoch 6, iter 140, loss: 6.192816734313965\n",
      "Epoch 6, iter 150, loss: 11.881525039672852\n",
      "Epoch 6, iter 160, loss: 8.290546417236328\n",
      "Epoch 6, iter 170, loss: 3.470465898513794\n",
      "Epoch 6, iter 180, loss: 14.735613822937012\n",
      "Epoch 6, iter 190, loss: 54.60525894165039\n",
      "Epoch 6, iter 200, loss: 7.414539813995361\n",
      "Epoch 6, iter 210, loss: 3.4992151260375977\n",
      "Epoch 6, iter 220, loss: 3.1799676418304443\n",
      "Epoch 6, iter 230, loss: 6.298614025115967\n",
      "Epoch 6, iter 240, loss: 16.036537170410156\n",
      "Epoch 6, iter 250, loss: 4.47987174987793\n",
      "Epoch 6, iter 260, loss: 5.098189353942871\n",
      "Epoch 6, iter 270, loss: 4.9412736892700195\n",
      "Epoch 6, iter 280, loss: 3.7748074531555176\n",
      "Epoch 6, iter 290, loss: 8.15809440612793\n",
      "Epoch 6, iter 300, loss: 4.535087585449219\n",
      "Epoch 6, iter 310, loss: 6.644448280334473\n",
      "Epoch 6, iter 320, loss: 9.438077926635742\n",
      "Epoch 6, iter 330, loss: 7.679777145385742\n",
      "Epoch 6, iter 340, loss: 3.697727680206299\n",
      "Epoch 6, iter 350, loss: 4.321998596191406\n",
      "Epoch 6, iter 360, loss: 4.687476634979248\n",
      "Epoch 6, iter 370, loss: 177.2368927001953\n",
      "Epoch 6, iter 380, loss: 7.058676242828369\n",
      "Epoch 6, iter 390, loss: 15.56899642944336\n",
      "Epoch 6, iter 400, loss: 4.626826763153076\n",
      "Epoch 6, iter 410, loss: 3.9612951278686523\n",
      "Epoch 6, iter 420, loss: 13.028092384338379\n",
      "Epoch 6, iter 430, loss: 7.505320072174072\n",
      "Epoch 6, iter 440, loss: 9.447493553161621\n",
      "Epoch 6, iter 450, loss: 20.870906829833984\n",
      "Epoch 6, iter 460, loss: 1.4184833765029907\n",
      "Epoch 6, iter 470, loss: 3.097951650619507\n",
      "Epoch 6, iter 480, loss: 2.444005250930786\n",
      "Epoch 6, iter 490, loss: 5.698736190795898\n",
      "Epoch 6, iter 500, loss: 1.9974045753479004\n",
      "Epoch 6, iter 510, loss: 2.8215975761413574\n",
      "Epoch 6, iter 520, loss: 7.210836410522461\n",
      "Epoch 6, iter 530, loss: 7.417507648468018\n",
      "Epoch 6, iter 540, loss: 11.108872413635254\n",
      "Epoch 6, iter 550, loss: 2.553927183151245\n",
      "Epoch 6, iter 560, loss: 1.9831024408340454\n",
      "Epoch 6, iter 570, loss: 5.955453395843506\n",
      "Epoch 6, iter 580, loss: 3.65724515914917\n",
      "Epoch 6, iter 590, loss: 5.667077541351318\n",
      "Epoch 6, iter 600, loss: 3.886467933654785\n",
      "Epoch 6, iter 610, loss: 5.925309658050537\n",
      "Epoch 6, iter 620, loss: 2.003633975982666\n",
      "Epoch 6, iter 630, loss: 2.0525121688842773\n",
      "Epoch 6, iter 640, loss: 2.5865888595581055\n",
      "Epoch 6, iter 650, loss: 1.9889262914657593\n",
      "Epoch 6, iter 660, loss: 9.159503936767578\n",
      "Epoch 6, iter 670, loss: 3.6747448444366455\n",
      "Epoch 6, iter 680, loss: 5.650966167449951\n",
      "Epoch 6, iter 690, loss: 4.948598861694336\n",
      "Epoch 6, iter 700, loss: 6.076599597930908\n",
      "Epoch 6, iter 710, loss: 10.481772422790527\n",
      "Epoch 6, iter 720, loss: 4.772349834442139\n",
      "Epoch 6, iter 730, loss: 2.189269542694092\n",
      "Epoch 6, iter 740, loss: 9.517203330993652\n",
      "Epoch 6, iter 750, loss: 9.592829704284668\n",
      "Epoch 6, iter 760, loss: 7.7848591804504395\n",
      "Epoch 6, iter 770, loss: 5.794713973999023\n",
      "Epoch 6, iter 780, loss: 6.3874311447143555\n",
      "Epoch 6, iter 790, loss: 1.6715633869171143\n",
      "Epoch 6, iter 800, loss: 2.302051067352295\n",
      "Epoch 6, iter 810, loss: 2.3500747680664062\n",
      "Epoch 6, iter 820, loss: 3.9862334728240967\n",
      "Model saved after epoch 7\n",
      "Epoch 7, iter 0, loss: 2.0880520343780518\n",
      "Epoch 7, iter 10, loss: 1.8551068305969238\n",
      "Epoch 7, iter 20, loss: 8.517512321472168\n",
      "Epoch 7, iter 30, loss: 3.6923677921295166\n",
      "Epoch 7, iter 40, loss: 6.225042343139648\n",
      "Epoch 7, iter 50, loss: 5.590890407562256\n",
      "Epoch 7, iter 60, loss: 2.1033759117126465\n",
      "Epoch 7, iter 70, loss: 6.623770713806152\n",
      "Epoch 7, iter 80, loss: 3.373101234436035\n",
      "Epoch 7, iter 90, loss: 2.795870304107666\n",
      "Epoch 7, iter 100, loss: 2.763460397720337\n",
      "Epoch 7, iter 110, loss: 3.7141025066375732\n",
      "Epoch 7, iter 120, loss: 7.619873046875\n",
      "Epoch 7, iter 130, loss: 6.665408611297607\n",
      "Epoch 7, iter 140, loss: 16.878007888793945\n",
      "Epoch 7, iter 150, loss: 5.058284282684326\n",
      "Epoch 7, iter 160, loss: 5.577693462371826\n",
      "Epoch 7, iter 170, loss: 5.171971797943115\n",
      "Epoch 7, iter 180, loss: 16.624547958374023\n",
      "Epoch 7, iter 190, loss: 115.88777923583984\n",
      "Epoch 7, iter 200, loss: 22.04953384399414\n",
      "Epoch 7, iter 210, loss: 7.6067705154418945\n",
      "Epoch 7, iter 220, loss: 2.0838842391967773\n",
      "Epoch 7, iter 230, loss: 2.454040050506592\n",
      "Epoch 7, iter 240, loss: 17.412160873413086\n",
      "Epoch 7, iter 250, loss: 6.359799385070801\n",
      "Epoch 7, iter 260, loss: 2.6966047286987305\n",
      "Epoch 7, iter 270, loss: 3.6679060459136963\n",
      "Epoch 7, iter 280, loss: 2.6463165283203125\n",
      "Epoch 7, iter 290, loss: 4.415020942687988\n",
      "Epoch 7, iter 300, loss: 12.218387603759766\n",
      "Epoch 7, iter 310, loss: 4.040152072906494\n",
      "Epoch 7, iter 320, loss: 26.988948822021484\n",
      "Epoch 7, iter 330, loss: 2.938169240951538\n",
      "Epoch 7, iter 340, loss: 3.286851644515991\n",
      "Epoch 7, iter 350, loss: 11.098827362060547\n",
      "Epoch 7, iter 360, loss: 3.4078335762023926\n",
      "Epoch 7, iter 370, loss: 3.8743276596069336\n",
      "Epoch 7, iter 380, loss: 2.1745195388793945\n",
      "Epoch 7, iter 390, loss: 2.174334764480591\n",
      "Epoch 7, iter 400, loss: 2.3416175842285156\n",
      "Epoch 7, iter 410, loss: 3.5490288734436035\n",
      "Epoch 7, iter 420, loss: 61.464927673339844\n",
      "Epoch 7, iter 430, loss: 3.074221611022949\n",
      "Epoch 7, iter 440, loss: 2.991786479949951\n",
      "Epoch 7, iter 450, loss: 3.8904197216033936\n",
      "Epoch 7, iter 460, loss: 2.8203721046447754\n",
      "Epoch 7, iter 470, loss: 12.457276344299316\n",
      "Epoch 7, iter 480, loss: 2.3251800537109375\n",
      "Epoch 7, iter 490, loss: 7.114927291870117\n",
      "Epoch 7, iter 500, loss: 1.41614830493927\n",
      "Epoch 7, iter 510, loss: 1.7071328163146973\n",
      "Epoch 7, iter 520, loss: 3.923614978790283\n",
      "Epoch 7, iter 530, loss: 2.7015130519866943\n",
      "Epoch 7, iter 540, loss: 19.267990112304688\n",
      "Epoch 7, iter 550, loss: 2.608518362045288\n",
      "Epoch 7, iter 560, loss: 10.19784164428711\n",
      "Epoch 7, iter 570, loss: 0.8982930779457092\n",
      "Epoch 7, iter 580, loss: 2.825822114944458\n",
      "Epoch 7, iter 590, loss: 5.586015224456787\n",
      "Epoch 7, iter 600, loss: 0.584636926651001\n",
      "Epoch 7, iter 610, loss: 12.245698928833008\n",
      "Epoch 7, iter 620, loss: 7.011753082275391\n",
      "Epoch 7, iter 630, loss: 14.318132400512695\n",
      "Epoch 7, iter 640, loss: 2.9302244186401367\n",
      "Epoch 7, iter 650, loss: 1.3977686166763306\n",
      "Epoch 7, iter 660, loss: 2.484713554382324\n",
      "Epoch 7, iter 670, loss: 1.4663900136947632\n",
      "Epoch 7, iter 680, loss: 7.023220062255859\n",
      "Epoch 7, iter 690, loss: 2.0562915802001953\n",
      "Epoch 7, iter 700, loss: 3.3689146041870117\n",
      "Epoch 7, iter 710, loss: 2.2955145835876465\n",
      "Epoch 7, iter 720, loss: 4.353097915649414\n",
      "Epoch 7, iter 730, loss: 4.418164253234863\n",
      "Epoch 7, iter 740, loss: 9.981572151184082\n",
      "Epoch 7, iter 750, loss: 14.322948455810547\n",
      "Epoch 7, iter 760, loss: 3.5533852577209473\n",
      "Epoch 7, iter 770, loss: 1.123753547668457\n",
      "Epoch 7, iter 780, loss: 2.7272841930389404\n",
      "Epoch 7, iter 790, loss: 2.760617256164551\n",
      "Epoch 7, iter 800, loss: 1.5028859376907349\n",
      "Epoch 7, iter 810, loss: 4.105562210083008\n",
      "Epoch 7, iter 820, loss: 1.889716386795044\n",
      "Model saved after epoch 8\n",
      "Epoch 8, iter 0, loss: 4.205352306365967\n",
      "Epoch 8, iter 10, loss: 1.998228669166565\n",
      "Epoch 8, iter 20, loss: 15.138303756713867\n",
      "Epoch 8, iter 30, loss: 2.137115955352783\n",
      "Epoch 8, iter 40, loss: 2.1985864639282227\n",
      "Epoch 8, iter 50, loss: 11.184393882751465\n",
      "Epoch 8, iter 60, loss: 1.106029987335205\n",
      "Epoch 8, iter 70, loss: 2.4764211177825928\n",
      "Epoch 8, iter 80, loss: 6.358172416687012\n",
      "Epoch 8, iter 90, loss: 2.740063428878784\n",
      "Epoch 8, iter 100, loss: 3.141183376312256\n",
      "Epoch 8, iter 110, loss: 1.8169708251953125\n",
      "Epoch 8, iter 120, loss: 6.413273811340332\n",
      "Epoch 8, iter 130, loss: 3.0209457874298096\n",
      "Epoch 8, iter 140, loss: 3.6852474212646484\n",
      "Epoch 8, iter 150, loss: 5.363094806671143\n",
      "Epoch 8, iter 160, loss: 6.521440029144287\n",
      "Epoch 8, iter 170, loss: 2.292452812194824\n",
      "Epoch 8, iter 180, loss: 3.57844614982605\n",
      "Epoch 8, iter 190, loss: 18.58253288269043\n",
      "Epoch 8, iter 200, loss: 3.688199996948242\n",
      "Epoch 8, iter 210, loss: 4.0046844482421875\n",
      "Epoch 8, iter 220, loss: 9.593389511108398\n",
      "Epoch 8, iter 230, loss: 2.043276309967041\n",
      "Epoch 8, iter 240, loss: 7.471189498901367\n",
      "Epoch 8, iter 250, loss: 8.374167442321777\n",
      "Epoch 8, iter 260, loss: 3.0131752490997314\n",
      "Epoch 8, iter 270, loss: 6.347363471984863\n",
      "Epoch 8, iter 280, loss: 2.561845064163208\n",
      "Epoch 8, iter 290, loss: 16.68851089477539\n",
      "Epoch 8, iter 300, loss: 8.212244987487793\n",
      "Epoch 8, iter 310, loss: 6.938373565673828\n",
      "Epoch 8, iter 320, loss: 12.654415130615234\n",
      "Epoch 8, iter 330, loss: 4.758359909057617\n",
      "Epoch 8, iter 340, loss: 5.4775614738464355\n",
      "Epoch 8, iter 350, loss: 7.3320441246032715\n",
      "Epoch 8, iter 360, loss: 4.706310272216797\n",
      "Epoch 8, iter 370, loss: 5.227412700653076\n",
      "Epoch 8, iter 380, loss: 1.0075547695159912\n",
      "Epoch 8, iter 390, loss: 7.304721832275391\n",
      "Epoch 8, iter 400, loss: 17.228473663330078\n",
      "Epoch 8, iter 410, loss: 6.358471870422363\n",
      "Epoch 8, iter 420, loss: 2.1086652278900146\n",
      "Epoch 8, iter 430, loss: 111.09956359863281\n",
      "Epoch 8, iter 440, loss: 3.9903647899627686\n",
      "Epoch 8, iter 450, loss: 26.163795471191406\n",
      "Epoch 8, iter 460, loss: 99.61869049072266\n",
      "Epoch 8, iter 470, loss: 2.2812917232513428\n",
      "Epoch 8, iter 480, loss: 2.7312121391296387\n",
      "Epoch 8, iter 490, loss: 1.4958680868148804\n",
      "Epoch 8, iter 500, loss: 2.1997010707855225\n",
      "Epoch 8, iter 510, loss: 5.064990520477295\n",
      "Epoch 8, iter 520, loss: 3.7297306060791016\n",
      "Epoch 8, iter 530, loss: 2.0311789512634277\n",
      "Epoch 8, iter 540, loss: 2.9320383071899414\n",
      "Epoch 8, iter 550, loss: 3.9085419178009033\n",
      "Epoch 8, iter 560, loss: 2.277738332748413\n",
      "Epoch 8, iter 570, loss: 10.66841983795166\n",
      "Epoch 8, iter 580, loss: 1.5926120281219482\n",
      "Epoch 8, iter 590, loss: 6.858197212219238\n",
      "Epoch 8, iter 600, loss: 4.8414506912231445\n",
      "Epoch 8, iter 610, loss: 3.7730016708374023\n",
      "Epoch 8, iter 620, loss: 2.58465313911438\n",
      "Epoch 8, iter 630, loss: 1.3122279644012451\n",
      "Epoch 8, iter 640, loss: 2.619992971420288\n",
      "Epoch 8, iter 650, loss: 3.5425474643707275\n",
      "Epoch 8, iter 660, loss: 10.65015983581543\n",
      "Epoch 8, iter 670, loss: 1.5539904832839966\n",
      "Epoch 8, iter 680, loss: 2.7149858474731445\n",
      "Epoch 8, iter 690, loss: 1.7336431741714478\n",
      "Epoch 8, iter 700, loss: 2.8719680309295654\n",
      "Epoch 8, iter 710, loss: 1.2948459386825562\n",
      "Epoch 8, iter 720, loss: 1.8795247077941895\n",
      "Epoch 8, iter 730, loss: 4.575220584869385\n",
      "Epoch 8, iter 740, loss: 3.314636707305908\n",
      "Epoch 8, iter 750, loss: 1.3623181581497192\n",
      "Epoch 8, iter 760, loss: 3.8003039360046387\n",
      "Epoch 8, iter 770, loss: 3.82140851020813\n",
      "Epoch 8, iter 780, loss: 8.287951469421387\n",
      "Epoch 8, iter 790, loss: 85.91923522949219\n",
      "Epoch 8, iter 800, loss: 5.276993751525879\n",
      "Epoch 8, iter 810, loss: 2.9089198112487793\n",
      "Epoch 8, iter 820, loss: 3.284437656402588\n",
      "Model saved after epoch 9\n",
      "Epoch 9, iter 0, loss: 2.4343109130859375\n",
      "Epoch 9, iter 10, loss: 5.461633205413818\n",
      "Epoch 9, iter 20, loss: 1.1571911573410034\n",
      "Epoch 9, iter 30, loss: 1.3327922821044922\n",
      "Epoch 9, iter 40, loss: 11.030332565307617\n",
      "Epoch 9, iter 50, loss: 1.480080008506775\n",
      "Epoch 9, iter 60, loss: 3.3763434886932373\n",
      "Epoch 9, iter 70, loss: 2.0711045265197754\n",
      "Epoch 9, iter 80, loss: 1.272971510887146\n",
      "Epoch 9, iter 90, loss: 3.9815516471862793\n",
      "Epoch 9, iter 100, loss: 0.7982683777809143\n",
      "Epoch 9, iter 110, loss: 2.366342544555664\n",
      "Epoch 9, iter 120, loss: 0.9560228586196899\n",
      "Epoch 9, iter 130, loss: 104.60961151123047\n",
      "Epoch 9, iter 140, loss: 3.50244402885437\n",
      "Epoch 9, iter 150, loss: 3.1182730197906494\n",
      "Epoch 9, iter 160, loss: 3.2470521926879883\n",
      "Epoch 9, iter 170, loss: 2.995364189147949\n",
      "Epoch 9, iter 180, loss: 0.9845888614654541\n",
      "Epoch 9, iter 190, loss: 2.4607110023498535\n",
      "Epoch 9, iter 200, loss: 1.567994475364685\n",
      "Epoch 9, iter 210, loss: 2.1204681396484375\n",
      "Epoch 9, iter 220, loss: 1.2660945653915405\n",
      "Epoch 9, iter 230, loss: 0.8142959475517273\n",
      "Epoch 9, iter 240, loss: 1.7846167087554932\n",
      "Epoch 9, iter 250, loss: 2.4496803283691406\n",
      "Epoch 9, iter 260, loss: 8.58043384552002\n",
      "Epoch 9, iter 270, loss: 1.2805302143096924\n",
      "Epoch 9, iter 280, loss: 2.546802043914795\n",
      "Epoch 9, iter 290, loss: 1.9624215364456177\n",
      "Epoch 9, iter 300, loss: 3.0770974159240723\n",
      "Epoch 9, iter 310, loss: 3.8343288898468018\n",
      "Epoch 9, iter 320, loss: 3.750803232192993\n",
      "Epoch 9, iter 330, loss: 8.231165885925293\n",
      "Epoch 9, iter 340, loss: 4.94908332824707\n",
      "Epoch 9, iter 350, loss: 2.847766160964966\n",
      "Epoch 9, iter 360, loss: 1.6185420751571655\n",
      "Epoch 9, iter 370, loss: 4.521911144256592\n",
      "Epoch 9, iter 380, loss: 16.875221252441406\n",
      "Epoch 9, iter 390, loss: 4.419394493103027\n",
      "Epoch 9, iter 400, loss: 5.009774684906006\n",
      "Epoch 9, iter 410, loss: 7.99894380569458\n",
      "Epoch 9, iter 420, loss: 6.413573741912842\n",
      "Epoch 9, iter 430, loss: 2.6813247203826904\n",
      "Epoch 9, iter 440, loss: 3.2861454486846924\n",
      "Epoch 9, iter 450, loss: 4.413878917694092\n",
      "Epoch 9, iter 460, loss: 1.360824465751648\n",
      "Epoch 9, iter 470, loss: 11.023632049560547\n",
      "Epoch 9, iter 480, loss: 5.2581963539123535\n",
      "Epoch 9, iter 490, loss: 13.264607429504395\n",
      "Epoch 9, iter 500, loss: 11.5597562789917\n",
      "Epoch 9, iter 510, loss: 16.76715850830078\n",
      "Epoch 9, iter 520, loss: 6.3509016036987305\n",
      "Epoch 9, iter 530, loss: 12.733591079711914\n",
      "Epoch 9, iter 540, loss: 128.94061279296875\n",
      "Epoch 9, iter 550, loss: 2.492823362350464\n",
      "Epoch 9, iter 560, loss: 3.2860496044158936\n",
      "Epoch 9, iter 570, loss: 3.3987739086151123\n",
      "Epoch 9, iter 580, loss: 3.229861259460449\n",
      "Epoch 9, iter 590, loss: 1.92185378074646\n",
      "Epoch 9, iter 600, loss: 1.8920351266860962\n",
      "Epoch 9, iter 610, loss: 3.0300705432891846\n",
      "Epoch 9, iter 620, loss: 3.310868978500366\n",
      "Epoch 9, iter 630, loss: 9.424871444702148\n",
      "Epoch 9, iter 640, loss: 22.369304656982422\n",
      "Epoch 9, iter 650, loss: 7.785439968109131\n",
      "Epoch 9, iter 660, loss: 15.052225112915039\n",
      "Epoch 9, iter 670, loss: 4.203676223754883\n",
      "Epoch 9, iter 680, loss: 1.7890077829360962\n",
      "Epoch 9, iter 690, loss: 3.5537283420562744\n",
      "Epoch 9, iter 700, loss: 1.2512816190719604\n",
      "Epoch 9, iter 710, loss: 2.3886048793792725\n",
      "Epoch 9, iter 720, loss: 6.207520008087158\n",
      "Epoch 9, iter 730, loss: 3.4943952560424805\n",
      "Epoch 9, iter 740, loss: 4.89386510848999\n",
      "Epoch 9, iter 750, loss: 2.2777678966522217\n",
      "Epoch 9, iter 760, loss: 2.585329532623291\n",
      "Epoch 9, iter 770, loss: 11.330889701843262\n",
      "Epoch 9, iter 780, loss: 17.95361328125\n",
      "Epoch 9, iter 790, loss: 3.019848585128784\n",
      "Epoch 9, iter 800, loss: 5.147207736968994\n",
      "Epoch 9, iter 810, loss: 3.532449722290039\n",
      "Epoch 9, iter 820, loss: 1.7812891006469727\n",
      "Model saved after epoch 10\n",
      "Epoch 10, iter 0, loss: 9.153812408447266\n",
      "Epoch 10, iter 10, loss: 4.309841156005859\n",
      "Epoch 10, iter 20, loss: 2.3731167316436768\n",
      "Epoch 10, iter 30, loss: 2.4585695266723633\n",
      "Epoch 10, iter 40, loss: 2.5151243209838867\n",
      "Epoch 10, iter 50, loss: 1.8517251014709473\n",
      "Epoch 10, iter 60, loss: 1.0332975387573242\n",
      "Epoch 10, iter 70, loss: 7.727437973022461\n",
      "Epoch 10, iter 80, loss: 3.2401175498962402\n",
      "Epoch 10, iter 90, loss: 2.1469292640686035\n",
      "Epoch 10, iter 100, loss: 3.02462100982666\n",
      "Epoch 10, iter 110, loss: 316.9930725097656\n",
      "Epoch 10, iter 120, loss: 2.4940223693847656\n",
      "Epoch 10, iter 130, loss: 9.398263931274414\n",
      "Epoch 10, iter 140, loss: 1.9485689401626587\n",
      "Epoch 10, iter 150, loss: 2.7076001167297363\n",
      "Epoch 10, iter 160, loss: 5.820258140563965\n",
      "Epoch 10, iter 170, loss: 75.6724624633789\n",
      "Epoch 10, iter 180, loss: 12.083919525146484\n",
      "Epoch 10, iter 190, loss: 4.5489277839660645\n",
      "Epoch 10, iter 200, loss: 2.7617058753967285\n",
      "Epoch 10, iter 210, loss: 4.671629905700684\n",
      "Epoch 10, iter 220, loss: 5.532517910003662\n",
      "Epoch 10, iter 230, loss: 102.63374328613281\n",
      "Epoch 10, iter 240, loss: 1.5186142921447754\n",
      "Epoch 10, iter 250, loss: 5.879705429077148\n",
      "Epoch 10, iter 260, loss: 3.21012282371521\n",
      "Epoch 10, iter 270, loss: 2.2859373092651367\n",
      "Epoch 10, iter 280, loss: 4.750852108001709\n",
      "Epoch 10, iter 290, loss: 1.6488004922866821\n",
      "Epoch 10, iter 300, loss: 1.8778842687606812\n",
      "Epoch 10, iter 310, loss: 16.489164352416992\n",
      "Epoch 10, iter 320, loss: 8.922019958496094\n",
      "Epoch 10, iter 330, loss: 1.2460578680038452\n",
      "Epoch 10, iter 340, loss: 5.572160720825195\n",
      "Epoch 10, iter 350, loss: 8.737414360046387\n",
      "Epoch 10, iter 360, loss: 2.839416265487671\n",
      "Epoch 10, iter 370, loss: 4.451303005218506\n",
      "Epoch 10, iter 380, loss: 3.2826473712921143\n",
      "Epoch 10, iter 390, loss: 1.8927533626556396\n",
      "Epoch 10, iter 400, loss: 1.1057319641113281\n",
      "Epoch 10, iter 410, loss: 1.5581177473068237\n",
      "Epoch 10, iter 420, loss: 1.3840070962905884\n",
      "Epoch 10, iter 430, loss: 1.2267578840255737\n",
      "Epoch 10, iter 440, loss: 4.747818946838379\n",
      "Epoch 10, iter 450, loss: 2.476498603820801\n",
      "Epoch 10, iter 460, loss: 11.094202995300293\n",
      "Epoch 10, iter 470, loss: 0.3530427813529968\n",
      "Epoch 10, iter 480, loss: 1.2638577222824097\n",
      "Epoch 10, iter 490, loss: 1.5896023511886597\n",
      "Epoch 10, iter 500, loss: 3.812471628189087\n",
      "Epoch 10, iter 510, loss: 2.827488899230957\n",
      "Epoch 10, iter 520, loss: 1.63487708568573\n",
      "Epoch 10, iter 530, loss: 4.4086198806762695\n",
      "Epoch 10, iter 540, loss: 2.559504270553589\n",
      "Epoch 10, iter 550, loss: 1.8008811473846436\n",
      "Epoch 10, iter 560, loss: 0.9562045931816101\n",
      "Epoch 10, iter 570, loss: 0.9058432579040527\n",
      "Epoch 10, iter 580, loss: 2.224626302719116\n",
      "Epoch 10, iter 590, loss: 9.316454887390137\n",
      "Epoch 10, iter 600, loss: 1.809342384338379\n",
      "Epoch 10, iter 610, loss: 3.686580181121826\n",
      "Epoch 10, iter 620, loss: 2.216033458709717\n",
      "Epoch 10, iter 630, loss: 7.229375839233398\n",
      "Epoch 10, iter 640, loss: 1.7142767906188965\n",
      "Epoch 10, iter 650, loss: 4.785804748535156\n",
      "Epoch 10, iter 660, loss: 1.176866054534912\n",
      "Epoch 10, iter 670, loss: 4.4141645431518555\n",
      "Epoch 10, iter 680, loss: 2.2254979610443115\n",
      "Epoch 10, iter 690, loss: 2.9559991359710693\n",
      "Epoch 10, iter 700, loss: 2.7599875926971436\n",
      "Epoch 10, iter 710, loss: 1.488746166229248\n",
      "Epoch 10, iter 720, loss: 2.1400952339172363\n",
      "Epoch 10, iter 730, loss: 4.643197536468506\n",
      "Epoch 10, iter 740, loss: 4.7879533767700195\n",
      "Epoch 10, iter 750, loss: 6.593893051147461\n",
      "Epoch 10, iter 760, loss: 97.47798156738281\n",
      "Epoch 10, iter 770, loss: 0.6032407283782959\n",
      "Epoch 10, iter 780, loss: 1.9681494235992432\n",
      "Epoch 10, iter 790, loss: 1.13043212890625\n",
      "Epoch 10, iter 800, loss: 1.697298288345337\n",
      "Epoch 10, iter 810, loss: 2.208951473236084\n",
      "Epoch 10, iter 820, loss: 8.948957443237305\n",
      "Model saved after epoch 11\n",
      "Epoch 11, iter 0, loss: 1.700526475906372\n",
      "Epoch 11, iter 10, loss: 1.2035452127456665\n",
      "Epoch 11, iter 20, loss: 1.8502614498138428\n",
      "Epoch 11, iter 30, loss: 1.171072244644165\n",
      "Epoch 11, iter 40, loss: 2.5267574787139893\n",
      "Epoch 11, iter 50, loss: 1.2010693550109863\n",
      "Epoch 11, iter 60, loss: 0.986922025680542\n",
      "Epoch 11, iter 70, loss: 3.2583765983581543\n",
      "Epoch 11, iter 80, loss: 1.6347670555114746\n",
      "Epoch 11, iter 90, loss: 4.082281589508057\n",
      "Epoch 11, iter 100, loss: 2.090970754623413\n",
      "Epoch 11, iter 110, loss: 1.06549870967865\n",
      "Epoch 11, iter 120, loss: 3.105487108230591\n",
      "Epoch 11, iter 130, loss: 1.6884772777557373\n",
      "Epoch 11, iter 140, loss: 1.664080023765564\n",
      "Epoch 11, iter 150, loss: 2.7084546089172363\n",
      "Epoch 11, iter 160, loss: 3.175105571746826\n",
      "Epoch 11, iter 170, loss: 2.8462040424346924\n",
      "Epoch 11, iter 180, loss: 0.5340667963027954\n",
      "Epoch 11, iter 190, loss: 2.776108741760254\n",
      "Epoch 11, iter 200, loss: 2.9640138149261475\n",
      "Epoch 11, iter 210, loss: 67.53227996826172\n",
      "Epoch 11, iter 220, loss: 2.9307682514190674\n",
      "Epoch 11, iter 230, loss: 1.6654366254806519\n",
      "Epoch 11, iter 240, loss: 1.019274115562439\n",
      "Epoch 11, iter 250, loss: 1.141668438911438\n",
      "Epoch 11, iter 260, loss: 17.123088836669922\n",
      "Epoch 11, iter 270, loss: 2.0998473167419434\n",
      "Epoch 11, iter 280, loss: 0.5248164534568787\n",
      "Epoch 11, iter 290, loss: 0.7016599178314209\n",
      "Epoch 11, iter 300, loss: 2.804781436920166\n",
      "Epoch 11, iter 310, loss: 1.8037610054016113\n",
      "Epoch 11, iter 320, loss: 1.8412911891937256\n",
      "Epoch 11, iter 330, loss: 2.1712045669555664\n",
      "Epoch 11, iter 340, loss: 3.386040449142456\n",
      "Epoch 11, iter 350, loss: 1.3017618656158447\n",
      "Epoch 11, iter 360, loss: 2.3854100704193115\n",
      "Epoch 11, iter 370, loss: 2.2756619453430176\n",
      "Epoch 11, iter 380, loss: 1.6486691236495972\n",
      "Epoch 11, iter 390, loss: 3.952326774597168\n",
      "Epoch 11, iter 400, loss: 2.490746259689331\n",
      "Epoch 11, iter 410, loss: 1.0139641761779785\n",
      "Epoch 11, iter 420, loss: 1.799129843711853\n",
      "Epoch 11, iter 430, loss: 3.462251663208008\n",
      "Epoch 11, iter 440, loss: 3.0674946308135986\n",
      "Epoch 11, iter 450, loss: 0.8749749660491943\n",
      "Epoch 11, iter 460, loss: 16.502527236938477\n",
      "Epoch 11, iter 470, loss: 4.058462142944336\n",
      "Epoch 11, iter 480, loss: 1.4557017087936401\n",
      "Epoch 11, iter 490, loss: 8.745494842529297\n",
      "Epoch 11, iter 500, loss: 1.864100694656372\n",
      "Epoch 11, iter 510, loss: 5.259366035461426\n",
      "Epoch 11, iter 520, loss: 0.8358767628669739\n",
      "Epoch 11, iter 530, loss: 12.019728660583496\n",
      "Epoch 11, iter 540, loss: 1.7761132717132568\n",
      "Epoch 11, iter 550, loss: 2.7583882808685303\n",
      "Epoch 11, iter 560, loss: 1.774078607559204\n",
      "Epoch 11, iter 570, loss: 2.014373302459717\n",
      "Epoch 11, iter 580, loss: 74.49247741699219\n",
      "Epoch 11, iter 590, loss: 0.9121088981628418\n",
      "Epoch 11, iter 600, loss: 0.335276335477829\n",
      "Epoch 11, iter 610, loss: 7.32993745803833\n",
      "Epoch 11, iter 620, loss: 1.5658364295959473\n",
      "Epoch 11, iter 630, loss: 3.311666250228882\n",
      "Epoch 11, iter 640, loss: 1.9110740423202515\n",
      "Epoch 11, iter 650, loss: 1.9947350025177002\n",
      "Epoch 11, iter 660, loss: 1.0243618488311768\n",
      "Epoch 11, iter 670, loss: 0.911396324634552\n",
      "Epoch 11, iter 680, loss: 3.325265645980835\n",
      "Epoch 11, iter 690, loss: 2.7521708011627197\n",
      "Epoch 11, iter 700, loss: 0.6701769232749939\n",
      "Epoch 11, iter 710, loss: 1.4686979055404663\n",
      "Epoch 11, iter 720, loss: 2.2487378120422363\n",
      "Epoch 11, iter 730, loss: 3.4979076385498047\n",
      "Epoch 11, iter 740, loss: 2.033088207244873\n",
      "Epoch 11, iter 750, loss: 1.164167046546936\n",
      "Epoch 11, iter 760, loss: 1.954313039779663\n",
      "Epoch 11, iter 770, loss: 0.9954851269721985\n",
      "Epoch 11, iter 780, loss: 2.137725591659546\n",
      "Epoch 11, iter 790, loss: 3.032109022140503\n",
      "Epoch 11, iter 800, loss: 1.4689327478408813\n",
      "Epoch 11, iter 810, loss: 1.8726142644882202\n",
      "Epoch 11, iter 820, loss: 1.093029499053955\n",
      "Model saved after epoch 12\n",
      "Epoch 12, iter 0, loss: 2.8960087299346924\n",
      "Epoch 12, iter 10, loss: 4.031800746917725\n",
      "Epoch 12, iter 20, loss: 1.4708038568496704\n",
      "Epoch 12, iter 30, loss: 2.834683656692505\n",
      "Epoch 12, iter 40, loss: 1.7083557844161987\n",
      "Epoch 12, iter 50, loss: 1.3579325675964355\n",
      "Epoch 12, iter 60, loss: 1.2841143608093262\n",
      "Epoch 12, iter 70, loss: 0.9298743009567261\n",
      "Epoch 12, iter 80, loss: 1.2039754390716553\n",
      "Epoch 12, iter 90, loss: 11.82036304473877\n",
      "Epoch 12, iter 100, loss: 1.3370593786239624\n",
      "Epoch 12, iter 110, loss: 1.101813793182373\n",
      "Epoch 12, iter 120, loss: 0.5743353962898254\n",
      "Epoch 12, iter 130, loss: 1.411790132522583\n",
      "Epoch 12, iter 140, loss: 1.656684160232544\n",
      "Epoch 12, iter 150, loss: 1.059993028640747\n",
      "Epoch 12, iter 160, loss: 0.47730979323387146\n",
      "Epoch 12, iter 170, loss: 0.7374571561813354\n",
      "Epoch 12, iter 180, loss: 0.811086118221283\n",
      "Epoch 12, iter 190, loss: 98.02561950683594\n",
      "Epoch 12, iter 200, loss: 1.6674596071243286\n",
      "Epoch 12, iter 210, loss: 0.9950766563415527\n",
      "Epoch 12, iter 220, loss: 0.711521565914154\n",
      "Epoch 12, iter 230, loss: 1.5664422512054443\n",
      "Epoch 12, iter 240, loss: 0.5207579731941223\n",
      "Epoch 12, iter 250, loss: 1.4638087749481201\n",
      "Epoch 12, iter 260, loss: 0.7082445025444031\n",
      "Epoch 12, iter 270, loss: 2.905186414718628\n",
      "Epoch 12, iter 280, loss: 1.092281460762024\n",
      "Epoch 12, iter 290, loss: 1.0199625492095947\n",
      "Epoch 12, iter 300, loss: 1.5814588069915771\n",
      "Epoch 12, iter 310, loss: 0.717096209526062\n",
      "Epoch 12, iter 320, loss: 1.114060640335083\n",
      "Epoch 12, iter 330, loss: 2.6847786903381348\n",
      "Epoch 12, iter 340, loss: 1.690885066986084\n",
      "Epoch 12, iter 350, loss: 0.6812909841537476\n",
      "Epoch 12, iter 360, loss: 1.5196254253387451\n",
      "Epoch 12, iter 370, loss: 2.083660125732422\n",
      "Epoch 12, iter 380, loss: 74.34645080566406\n",
      "Epoch 12, iter 390, loss: 3.745781183242798\n",
      "Epoch 12, iter 400, loss: 1.8298137187957764\n",
      "Epoch 12, iter 410, loss: 5.580377101898193\n",
      "Epoch 12, iter 420, loss: 2.45033597946167\n",
      "Epoch 12, iter 430, loss: 1.7087024450302124\n",
      "Epoch 12, iter 440, loss: 9.1907377243042\n",
      "Epoch 12, iter 450, loss: 4.866853713989258\n",
      "Epoch 12, iter 460, loss: 1.108270287513733\n",
      "Epoch 12, iter 470, loss: 1.776922583580017\n",
      "Epoch 12, iter 480, loss: 1.6382702589035034\n",
      "Epoch 12, iter 490, loss: 3.1275908946990967\n",
      "Epoch 12, iter 500, loss: 3.2900614738464355\n",
      "Epoch 12, iter 510, loss: 2.5022082328796387\n",
      "Epoch 12, iter 520, loss: 1.1350772380828857\n",
      "Epoch 12, iter 530, loss: 1.780928134918213\n",
      "Epoch 12, iter 540, loss: 2.9430761337280273\n",
      "Epoch 12, iter 550, loss: 2.8162026405334473\n",
      "Epoch 12, iter 560, loss: 2.638686180114746\n",
      "Epoch 12, iter 570, loss: 1.044940710067749\n",
      "Epoch 12, iter 580, loss: 1.8230926990509033\n",
      "Epoch 12, iter 590, loss: 0.9578816890716553\n",
      "Epoch 12, iter 600, loss: 4.373510360717773\n",
      "Epoch 12, iter 610, loss: 3.1811437606811523\n",
      "Epoch 12, iter 620, loss: 12.164389610290527\n",
      "Epoch 12, iter 630, loss: 132.13821411132812\n",
      "Epoch 12, iter 640, loss: 5.475675106048584\n",
      "Epoch 12, iter 650, loss: 6.912701606750488\n",
      "Epoch 12, iter 660, loss: 6.644649982452393\n",
      "Epoch 12, iter 670, loss: 1.5551286935806274\n",
      "Epoch 12, iter 680, loss: 5.215704917907715\n",
      "Epoch 12, iter 690, loss: 2.355283498764038\n",
      "Epoch 12, iter 700, loss: 10.5238037109375\n",
      "Epoch 12, iter 710, loss: 3.9341588020324707\n",
      "Epoch 12, iter 720, loss: 2.0803942680358887\n",
      "Epoch 12, iter 730, loss: 4.716407299041748\n",
      "Epoch 12, iter 740, loss: 0.8141545653343201\n",
      "Epoch 12, iter 750, loss: 5.987875938415527\n",
      "Epoch 12, iter 760, loss: 6.770553112030029\n",
      "Epoch 12, iter 770, loss: 7.627943515777588\n",
      "Epoch 12, iter 780, loss: 1.1609992980957031\n",
      "Epoch 12, iter 790, loss: 3.440554141998291\n",
      "Epoch 12, iter 800, loss: 10.833810806274414\n",
      "Epoch 12, iter 810, loss: 0.8212814927101135\n",
      "Epoch 12, iter 820, loss: 0.6216233372688293\n",
      "Model saved after epoch 13\n",
      "Epoch 13, iter 0, loss: 1.0696723461151123\n",
      "Epoch 13, iter 10, loss: 5.247733116149902\n",
      "Epoch 13, iter 20, loss: 1.863708257675171\n",
      "Epoch 13, iter 30, loss: 1.068405270576477\n",
      "Epoch 13, iter 40, loss: 2.0185623168945312\n",
      "Epoch 13, iter 50, loss: 2.2944860458374023\n",
      "Epoch 13, iter 60, loss: 1.2684853076934814\n",
      "Epoch 13, iter 70, loss: 4.177925109863281\n",
      "Epoch 13, iter 80, loss: 2.248239517211914\n",
      "Epoch 13, iter 90, loss: 3.2873494625091553\n",
      "Epoch 13, iter 100, loss: 9.617919921875\n",
      "Epoch 13, iter 110, loss: 1.4179331064224243\n",
      "Epoch 13, iter 120, loss: 7.1679582595825195\n",
      "Epoch 13, iter 130, loss: 4.119088649749756\n",
      "Epoch 13, iter 140, loss: 1.2347835302352905\n",
      "Epoch 13, iter 150, loss: 1.6827033758163452\n",
      "Epoch 13, iter 160, loss: 4.668421268463135\n",
      "Epoch 13, iter 170, loss: 1.72370445728302\n",
      "Epoch 13, iter 180, loss: 9.665240287780762\n",
      "Epoch 13, iter 190, loss: 1.2740705013275146\n",
      "Epoch 13, iter 200, loss: 2.0575785636901855\n",
      "Epoch 13, iter 210, loss: 1.9700387716293335\n",
      "Epoch 13, iter 220, loss: 1.1529289484024048\n",
      "Epoch 13, iter 230, loss: 0.8018419146537781\n",
      "Epoch 13, iter 240, loss: 1.548506259918213\n",
      "Epoch 13, iter 250, loss: 0.6322678327560425\n",
      "Epoch 13, iter 260, loss: 0.7396548390388489\n",
      "Epoch 13, iter 270, loss: 3.5098986625671387\n",
      "Epoch 13, iter 280, loss: 2.961921215057373\n",
      "Epoch 13, iter 290, loss: 2.029982328414917\n",
      "Epoch 13, iter 300, loss: 2.981778621673584\n",
      "Epoch 13, iter 310, loss: 0.8529009222984314\n",
      "Epoch 13, iter 320, loss: 1.7758325338363647\n",
      "Epoch 13, iter 330, loss: 0.9680719971656799\n",
      "Epoch 13, iter 340, loss: 0.3517724573612213\n",
      "Epoch 13, iter 350, loss: 2.020456075668335\n",
      "Epoch 13, iter 360, loss: 0.9272217750549316\n",
      "Epoch 13, iter 370, loss: 0.5742170214653015\n",
      "Epoch 13, iter 380, loss: 1.2290582656860352\n",
      "Epoch 13, iter 390, loss: 1.5868560075759888\n",
      "Epoch 13, iter 400, loss: 1.092961072921753\n",
      "Epoch 13, iter 410, loss: 13.633405685424805\n",
      "Epoch 13, iter 420, loss: 1.0444226264953613\n",
      "Epoch 13, iter 430, loss: 2.5344064235687256\n",
      "Epoch 13, iter 440, loss: 3.308717966079712\n",
      "Epoch 13, iter 450, loss: 2.6796984672546387\n",
      "Epoch 13, iter 460, loss: 2.586350679397583\n",
      "Epoch 13, iter 470, loss: 1.55887770652771\n",
      "Epoch 13, iter 480, loss: 70.44705963134766\n",
      "Epoch 13, iter 490, loss: 1.9383140802383423\n",
      "Epoch 13, iter 500, loss: 14.1721830368042\n",
      "Epoch 13, iter 510, loss: 1.1657835245132446\n",
      "Epoch 13, iter 520, loss: 0.9097707271575928\n",
      "Epoch 13, iter 530, loss: 1.0533164739608765\n",
      "Epoch 13, iter 540, loss: 5.858159065246582\n",
      "Epoch 13, iter 550, loss: 4.527594566345215\n",
      "Epoch 13, iter 560, loss: 1.4470304250717163\n",
      "Epoch 13, iter 570, loss: 2.6389999389648438\n",
      "Epoch 13, iter 580, loss: 1.1368448734283447\n",
      "Epoch 13, iter 590, loss: 0.7020834684371948\n",
      "Epoch 13, iter 600, loss: 1.4815747737884521\n",
      "Epoch 13, iter 610, loss: 2.2796714305877686\n",
      "Epoch 13, iter 620, loss: 2.6315743923187256\n",
      "Epoch 13, iter 630, loss: 2.0394339561462402\n",
      "Epoch 13, iter 640, loss: 1.8247686624526978\n",
      "Epoch 13, iter 650, loss: 1.2780463695526123\n",
      "Epoch 13, iter 660, loss: 1.2433202266693115\n",
      "Epoch 13, iter 670, loss: 1.5949689149856567\n",
      "Epoch 13, iter 680, loss: 1.8997516632080078\n",
      "Epoch 13, iter 690, loss: 2.223414897918701\n",
      "Epoch 13, iter 700, loss: 3.8823153972625732\n",
      "Epoch 13, iter 710, loss: 4.199716567993164\n",
      "Epoch 13, iter 720, loss: 121.7294921875\n",
      "Epoch 13, iter 730, loss: 2.995054006576538\n",
      "Epoch 13, iter 740, loss: 2.831636905670166\n",
      "Epoch 13, iter 750, loss: 0.7213268876075745\n",
      "Epoch 13, iter 760, loss: 6.7951459884643555\n",
      "Epoch 13, iter 770, loss: 1.759315848350525\n",
      "Epoch 13, iter 780, loss: 2.129669189453125\n",
      "Epoch 13, iter 790, loss: 1.4496711492538452\n",
      "Epoch 13, iter 800, loss: 1.1202235221862793\n",
      "Epoch 13, iter 810, loss: 1.7597806453704834\n",
      "Epoch 13, iter 820, loss: 1.4339550733566284\n",
      "Model saved after epoch 14\n",
      "Epoch 14, iter 0, loss: 0.850864827632904\n",
      "Epoch 14, iter 10, loss: 1.3871408700942993\n",
      "Epoch 14, iter 20, loss: 0.6817542910575867\n",
      "Epoch 14, iter 30, loss: 1.3342913389205933\n",
      "Epoch 14, iter 40, loss: 1.9800117015838623\n",
      "Epoch 14, iter 50, loss: 1.6960541009902954\n",
      "Epoch 14, iter 60, loss: 1.422338604927063\n",
      "Epoch 14, iter 70, loss: 0.7717829346656799\n",
      "Epoch 14, iter 80, loss: 0.6743114590644836\n",
      "Epoch 14, iter 90, loss: 2.242511510848999\n",
      "Epoch 14, iter 100, loss: 1.5305012464523315\n",
      "Epoch 14, iter 110, loss: 0.48079925775527954\n",
      "Epoch 14, iter 120, loss: 1.7149088382720947\n",
      "Epoch 14, iter 130, loss: 2.89132022857666\n",
      "Epoch 14, iter 140, loss: 1.2298882007598877\n",
      "Epoch 14, iter 150, loss: 0.8874178528785706\n",
      "Epoch 14, iter 160, loss: 1.7508492469787598\n",
      "Epoch 14, iter 170, loss: 0.5193707942962646\n",
      "Epoch 14, iter 180, loss: 0.8663864731788635\n",
      "Epoch 14, iter 190, loss: 0.7446687817573547\n",
      "Epoch 14, iter 200, loss: 1.8233582973480225\n",
      "Epoch 14, iter 210, loss: 2.6650543212890625\n",
      "Epoch 14, iter 220, loss: 0.77984219789505\n",
      "Epoch 14, iter 230, loss: 0.4352034628391266\n",
      "Epoch 14, iter 240, loss: 1.4164265394210815\n",
      "Epoch 14, iter 250, loss: 0.9877805709838867\n",
      "Epoch 14, iter 260, loss: 2.49293851852417\n",
      "Epoch 14, iter 270, loss: 1.7719128131866455\n",
      "Epoch 14, iter 280, loss: 1.637567162513733\n",
      "Epoch 14, iter 290, loss: 2.133803129196167\n",
      "Epoch 14, iter 300, loss: 1.6439205408096313\n",
      "Epoch 14, iter 310, loss: 0.8112300038337708\n",
      "Epoch 14, iter 320, loss: 0.8679263591766357\n",
      "Epoch 14, iter 330, loss: 11.179158210754395\n",
      "Epoch 14, iter 340, loss: 2.0307111740112305\n",
      "Epoch 14, iter 350, loss: 2.5611724853515625\n",
      "Epoch 14, iter 360, loss: 68.4322509765625\n",
      "Epoch 14, iter 370, loss: 1.3658993244171143\n",
      "Epoch 14, iter 380, loss: 0.7549446821212769\n",
      "Epoch 14, iter 390, loss: 2.240950107574463\n",
      "Epoch 14, iter 400, loss: 7.044039726257324\n",
      "Epoch 14, iter 410, loss: 0.9728505611419678\n",
      "Epoch 14, iter 420, loss: 0.7787509560585022\n",
      "Epoch 14, iter 430, loss: 0.4490988254547119\n",
      "Epoch 14, iter 440, loss: 1.5292325019836426\n",
      "Epoch 14, iter 450, loss: 2.265498161315918\n",
      "Epoch 14, iter 460, loss: 0.8884273767471313\n",
      "Epoch 14, iter 470, loss: 2.3089704513549805\n",
      "Epoch 14, iter 480, loss: 3.288954019546509\n",
      "Epoch 14, iter 490, loss: 1.0197222232818604\n",
      "Epoch 14, iter 500, loss: 2.59266996383667\n",
      "Epoch 14, iter 510, loss: 1.6655081510543823\n",
      "Epoch 14, iter 520, loss: 1.5918341875076294\n",
      "Epoch 14, iter 530, loss: 0.9320991039276123\n",
      "Epoch 14, iter 540, loss: 1.4334815740585327\n",
      "Epoch 14, iter 550, loss: 1.886924386024475\n",
      "Epoch 14, iter 560, loss: 0.318810373544693\n",
      "Epoch 14, iter 570, loss: 4.519619941711426\n",
      "Epoch 14, iter 580, loss: 2.3333866596221924\n",
      "Epoch 14, iter 590, loss: 2.2608208656311035\n",
      "Epoch 14, iter 600, loss: 1.4547536373138428\n",
      "Epoch 14, iter 610, loss: 1.9447453022003174\n",
      "Epoch 14, iter 620, loss: 1.0238312482833862\n",
      "Epoch 14, iter 630, loss: 1.9131367206573486\n",
      "Epoch 14, iter 640, loss: 2.135377883911133\n",
      "Epoch 14, iter 650, loss: 0.653066098690033\n",
      "Epoch 14, iter 660, loss: 2.3951902389526367\n",
      "Epoch 14, iter 670, loss: 10.66274642944336\n",
      "Epoch 14, iter 680, loss: 2.417987585067749\n",
      "Epoch 14, iter 690, loss: 0.7675320506095886\n",
      "Epoch 14, iter 700, loss: 1.3060705661773682\n",
      "Epoch 14, iter 710, loss: 1.8717427253723145\n",
      "Epoch 14, iter 720, loss: 3.778122663497925\n",
      "Epoch 14, iter 730, loss: 1.2381455898284912\n",
      "Epoch 14, iter 740, loss: 3.5958971977233887\n",
      "Epoch 14, iter 750, loss: 1.177605152130127\n",
      "Epoch 14, iter 760, loss: 2.175859212875366\n",
      "Epoch 14, iter 770, loss: 1.0811023712158203\n",
      "Epoch 14, iter 780, loss: 0.8256213665008545\n",
      "Epoch 14, iter 790, loss: 3.103658437728882\n",
      "Epoch 14, iter 800, loss: 2.010167121887207\n",
      "Epoch 14, iter 810, loss: 1.215830683708191\n",
      "Epoch 14, iter 820, loss: 4.979255676269531\n",
      "Model saved after epoch 15\n",
      "Epoch 15, iter 0, loss: 7.746699333190918\n",
      "Epoch 15, iter 10, loss: 2.0075783729553223\n",
      "Epoch 15, iter 20, loss: 3.4194700717926025\n",
      "Epoch 15, iter 30, loss: 37.95941162109375\n",
      "Epoch 15, iter 40, loss: 2.984114408493042\n",
      "Epoch 15, iter 50, loss: 2.8637633323669434\n",
      "Epoch 15, iter 60, loss: 4.417450428009033\n",
      "Epoch 15, iter 70, loss: 6.192205429077148\n",
      "Epoch 15, iter 80, loss: 3.535708427429199\n",
      "Epoch 15, iter 90, loss: 2.699986457824707\n",
      "Epoch 15, iter 100, loss: 3.603599786758423\n",
      "Epoch 15, iter 110, loss: 1.013604760169983\n",
      "Epoch 15, iter 120, loss: 1.5439099073410034\n",
      "Epoch 15, iter 130, loss: 1.0441772937774658\n",
      "Epoch 15, iter 140, loss: 0.8593969941139221\n",
      "Epoch 15, iter 150, loss: 0.7220847010612488\n",
      "Epoch 15, iter 160, loss: 2.464895725250244\n",
      "Epoch 15, iter 170, loss: 4.572185039520264\n",
      "Epoch 15, iter 180, loss: 4.2812018394470215\n",
      "Epoch 15, iter 190, loss: 2.400283098220825\n",
      "Epoch 15, iter 200, loss: 0.9103730320930481\n",
      "Epoch 15, iter 210, loss: 1.2573150396347046\n",
      "Epoch 15, iter 220, loss: 1.0450552701950073\n",
      "Epoch 15, iter 230, loss: 1.812659502029419\n",
      "Epoch 15, iter 240, loss: 2.109998941421509\n",
      "Epoch 15, iter 250, loss: 2.6160953044891357\n",
      "Epoch 15, iter 260, loss: 3.1498754024505615\n",
      "Epoch 15, iter 270, loss: 3.382225275039673\n",
      "Epoch 15, iter 280, loss: 5.23486852645874\n",
      "Epoch 15, iter 290, loss: 3.544154644012451\n",
      "Epoch 15, iter 300, loss: 9.893406867980957\n",
      "Epoch 15, iter 310, loss: 7.796713829040527\n",
      "Epoch 15, iter 320, loss: 1.234546184539795\n",
      "Epoch 15, iter 330, loss: 5.5022969245910645\n",
      "Epoch 15, iter 340, loss: 1.7952253818511963\n",
      "Epoch 15, iter 350, loss: 2.3136887550354004\n",
      "Epoch 15, iter 360, loss: 6.77243709564209\n",
      "Epoch 15, iter 370, loss: 1.5153151750564575\n",
      "Epoch 15, iter 380, loss: 1.7751528024673462\n",
      "Epoch 15, iter 390, loss: 0.7044710516929626\n",
      "Epoch 15, iter 400, loss: 1.039257287979126\n",
      "Epoch 15, iter 410, loss: 0.9255486726760864\n",
      "Epoch 15, iter 420, loss: 0.44032248854637146\n",
      "Epoch 15, iter 430, loss: 3.41556453704834\n",
      "Epoch 15, iter 440, loss: 1.5112049579620361\n",
      "Epoch 15, iter 450, loss: 1.0322731733322144\n",
      "Epoch 15, iter 460, loss: 2.237036943435669\n",
      "Epoch 15, iter 470, loss: 2.3580265045166016\n",
      "Epoch 15, iter 480, loss: 3.432793378829956\n",
      "Epoch 15, iter 490, loss: 0.48874902725219727\n",
      "Epoch 15, iter 500, loss: 0.8690153360366821\n",
      "Epoch 15, iter 510, loss: 0.9355839490890503\n",
      "Epoch 15, iter 520, loss: 2.487365484237671\n",
      "Epoch 15, iter 530, loss: 0.4745998680591583\n",
      "Epoch 15, iter 540, loss: 1.753731369972229\n",
      "Epoch 15, iter 550, loss: 1.1375439167022705\n",
      "Epoch 15, iter 560, loss: 2.516956329345703\n",
      "Epoch 15, iter 570, loss: 10.49939250946045\n",
      "Epoch 15, iter 580, loss: 0.5865079760551453\n",
      "Epoch 15, iter 590, loss: 2.0245168209075928\n",
      "Epoch 15, iter 600, loss: 0.5937608480453491\n",
      "Epoch 15, iter 610, loss: 0.9493836164474487\n",
      "Epoch 15, iter 620, loss: 0.8478325605392456\n",
      "Epoch 15, iter 630, loss: 0.5445587635040283\n",
      "Epoch 15, iter 640, loss: 1.0616258382797241\n",
      "Epoch 15, iter 650, loss: 1.2833315134048462\n",
      "Epoch 15, iter 660, loss: 2.2632598876953125\n",
      "Epoch 15, iter 670, loss: 1.154529333114624\n",
      "Epoch 15, iter 680, loss: 0.28344327211380005\n",
      "Epoch 15, iter 690, loss: 3.74017071723938\n",
      "Epoch 15, iter 700, loss: 1.2039830684661865\n",
      "Epoch 15, iter 710, loss: 0.4865224361419678\n",
      "Epoch 15, iter 720, loss: 1.4930927753448486\n",
      "Epoch 15, iter 730, loss: 1.4382059574127197\n",
      "Epoch 15, iter 740, loss: 1.9801946878433228\n",
      "Epoch 15, iter 750, loss: 0.9726033806800842\n",
      "Epoch 15, iter 760, loss: 2.6181674003601074\n",
      "Epoch 15, iter 770, loss: 1.2440567016601562\n",
      "Epoch 15, iter 780, loss: 1.7567905187606812\n",
      "Epoch 15, iter 790, loss: 0.9599875211715698\n",
      "Epoch 15, iter 800, loss: 3.08314847946167\n",
      "Epoch 15, iter 810, loss: 2.163142204284668\n",
      "Epoch 15, iter 820, loss: 0.5716671347618103\n",
      "Model saved after epoch 16\n",
      "Epoch 16, iter 0, loss: 0.3950468897819519\n",
      "Epoch 16, iter 10, loss: 1.4560678005218506\n",
      "Epoch 16, iter 20, loss: 0.5940364003181458\n",
      "Epoch 16, iter 30, loss: 0.915612518787384\n",
      "Epoch 16, iter 40, loss: 1.6362348794937134\n",
      "Epoch 16, iter 50, loss: 1.9868643283843994\n",
      "Epoch 16, iter 60, loss: 1.178255319595337\n",
      "Epoch 16, iter 70, loss: 2.27583384513855\n",
      "Epoch 16, iter 80, loss: 0.7331645488739014\n",
      "Epoch 16, iter 90, loss: 0.5902574062347412\n",
      "Epoch 16, iter 100, loss: 0.8083986639976501\n",
      "Epoch 16, iter 110, loss: 0.6998308897018433\n",
      "Epoch 16, iter 120, loss: 33.51971435546875\n",
      "Epoch 16, iter 130, loss: 2.8153045177459717\n",
      "Epoch 16, iter 140, loss: 2.49293851852417\n",
      "Epoch 16, iter 150, loss: 0.5123855471611023\n",
      "Epoch 16, iter 160, loss: 2.0217010974884033\n",
      "Epoch 16, iter 170, loss: 1.5815874338150024\n",
      "Epoch 16, iter 180, loss: 0.5525900721549988\n",
      "Epoch 16, iter 190, loss: 2.57489013671875\n",
      "Epoch 16, iter 200, loss: 0.7050287127494812\n",
      "Epoch 16, iter 210, loss: 2.0499589443206787\n",
      "Epoch 16, iter 220, loss: 5.230682373046875\n",
      "Epoch 16, iter 230, loss: 1.2363104820251465\n",
      "Epoch 16, iter 240, loss: 7.28776216506958\n",
      "Epoch 16, iter 250, loss: 4.194269180297852\n",
      "Epoch 16, iter 260, loss: 0.7858688235282898\n",
      "Epoch 16, iter 270, loss: 2.273869514465332\n",
      "Epoch 16, iter 280, loss: 60.433982849121094\n",
      "Epoch 16, iter 290, loss: 0.7645423412322998\n",
      "Epoch 16, iter 300, loss: 1.8656712770462036\n",
      "Epoch 16, iter 310, loss: 3.4376380443573\n",
      "Epoch 16, iter 320, loss: 69.70153045654297\n",
      "Epoch 16, iter 330, loss: 0.965897798538208\n",
      "Epoch 16, iter 340, loss: 1.503395915031433\n",
      "Epoch 16, iter 350, loss: 39.36378479003906\n",
      "Epoch 16, iter 360, loss: 1.2369426488876343\n",
      "Epoch 16, iter 370, loss: 1.5787490606307983\n",
      "Epoch 16, iter 380, loss: 1.1646249294281006\n",
      "Epoch 16, iter 390, loss: 0.8978608250617981\n",
      "Epoch 16, iter 400, loss: 1.1303155422210693\n",
      "Epoch 16, iter 410, loss: 3.8010573387145996\n",
      "Epoch 16, iter 420, loss: 1.7482701539993286\n",
      "Epoch 16, iter 430, loss: 0.8100147843360901\n",
      "Epoch 16, iter 440, loss: 3.2069408893585205\n",
      "Epoch 16, iter 450, loss: 0.7364844083786011\n",
      "Epoch 16, iter 460, loss: 0.7754169702529907\n",
      "Epoch 16, iter 470, loss: 1.6354128122329712\n",
      "Epoch 16, iter 480, loss: 0.6035810708999634\n",
      "Epoch 16, iter 490, loss: 69.02454376220703\n",
      "Epoch 16, iter 500, loss: 1.2776657342910767\n",
      "Epoch 16, iter 510, loss: 2.0171916484832764\n",
      "Epoch 16, iter 520, loss: 1.706366777420044\n",
      "Epoch 16, iter 530, loss: 0.7276347875595093\n",
      "Epoch 16, iter 540, loss: 1.4994556903839111\n",
      "Epoch 16, iter 550, loss: 1.0829544067382812\n",
      "Epoch 16, iter 560, loss: 0.6737983822822571\n",
      "Epoch 16, iter 570, loss: 1.2426823377609253\n",
      "Epoch 16, iter 580, loss: 1.9821898937225342\n",
      "Epoch 16, iter 590, loss: 1.1009682416915894\n",
      "Epoch 16, iter 600, loss: 1.052520751953125\n",
      "Epoch 16, iter 610, loss: 2.431100368499756\n",
      "Epoch 16, iter 620, loss: 7.928431034088135\n",
      "Epoch 16, iter 630, loss: 0.7257320284843445\n",
      "Epoch 16, iter 640, loss: 0.7541308999061584\n",
      "Epoch 16, iter 650, loss: 0.9810554385185242\n",
      "Epoch 16, iter 660, loss: 1.4841673374176025\n",
      "Epoch 16, iter 670, loss: 9.953388214111328\n",
      "Epoch 16, iter 680, loss: 1.3382567167282104\n",
      "Epoch 16, iter 690, loss: 0.7177437543869019\n",
      "Epoch 16, iter 700, loss: 1.168701410293579\n",
      "Epoch 16, iter 710, loss: 1.3364912271499634\n",
      "Epoch 16, iter 720, loss: 5.916963577270508\n",
      "Epoch 16, iter 730, loss: 0.34121549129486084\n",
      "Epoch 16, iter 740, loss: 1.4683620929718018\n",
      "Epoch 16, iter 750, loss: 2.416110038757324\n",
      "Epoch 16, iter 760, loss: 0.5240602493286133\n",
      "Epoch 16, iter 770, loss: 1.1145280599594116\n",
      "Epoch 16, iter 780, loss: 0.8593915700912476\n",
      "Epoch 16, iter 790, loss: 0.44075465202331543\n",
      "Epoch 16, iter 800, loss: 1.4995795488357544\n",
      "Epoch 16, iter 810, loss: 1.1157705783843994\n",
      "Epoch 16, iter 820, loss: 0.7323142886161804\n",
      "Model saved after epoch 17\n",
      "Epoch 17, iter 0, loss: 0.925784170627594\n",
      "Epoch 17, iter 10, loss: 1.9369728565216064\n",
      "Epoch 17, iter 20, loss: 0.4836866855621338\n",
      "Epoch 17, iter 30, loss: 0.4761776030063629\n",
      "Epoch 17, iter 40, loss: 0.7968974709510803\n",
      "Epoch 17, iter 50, loss: 1.370332956314087\n",
      "Epoch 17, iter 60, loss: 1.9235635995864868\n",
      "Epoch 17, iter 70, loss: 0.4855579137802124\n",
      "Epoch 17, iter 80, loss: 1.2828963994979858\n",
      "Epoch 17, iter 90, loss: 2.226871967315674\n",
      "Epoch 17, iter 100, loss: 0.28500986099243164\n",
      "Epoch 17, iter 110, loss: 1.3857694864273071\n",
      "Epoch 17, iter 120, loss: 0.5350196361541748\n",
      "Epoch 17, iter 130, loss: 0.7801794409751892\n",
      "Epoch 17, iter 140, loss: 1.5888431072235107\n",
      "Epoch 17, iter 150, loss: 2.094650983810425\n",
      "Epoch 17, iter 160, loss: 0.6713297963142395\n",
      "Epoch 17, iter 170, loss: 1.1079518795013428\n",
      "Epoch 17, iter 180, loss: 2.442194700241089\n",
      "Epoch 17, iter 190, loss: 1.3151752948760986\n",
      "Epoch 17, iter 200, loss: 1.8741484880447388\n",
      "Epoch 17, iter 210, loss: 0.4604555070400238\n",
      "Epoch 17, iter 220, loss: 0.9313926696777344\n",
      "Epoch 17, iter 230, loss: 1.6194950342178345\n",
      "Epoch 17, iter 240, loss: 3.1405880451202393\n",
      "Epoch 17, iter 250, loss: 1.8937627077102661\n",
      "Epoch 17, iter 260, loss: 1.340051531791687\n",
      "Epoch 17, iter 270, loss: 1.0821466445922852\n",
      "Epoch 17, iter 280, loss: 6.711382865905762\n",
      "Epoch 17, iter 290, loss: 1.0882551670074463\n",
      "Epoch 17, iter 300, loss: 2.47259259223938\n",
      "Epoch 17, iter 310, loss: 0.40329205989837646\n",
      "Epoch 17, iter 320, loss: 4.571112155914307\n",
      "Epoch 17, iter 330, loss: 0.7146280407905579\n",
      "Epoch 17, iter 340, loss: 1.651830792427063\n",
      "Epoch 17, iter 350, loss: 12.207307815551758\n",
      "Epoch 17, iter 360, loss: 0.9692196846008301\n",
      "Epoch 17, iter 370, loss: 1.5092389583587646\n",
      "Epoch 17, iter 380, loss: 4.80214786529541\n",
      "Epoch 17, iter 390, loss: 0.5657122135162354\n",
      "Epoch 17, iter 400, loss: 46.02324676513672\n",
      "Epoch 17, iter 410, loss: 110.96159362792969\n",
      "Epoch 17, iter 420, loss: 1.027552843093872\n",
      "Epoch 17, iter 430, loss: 2.018700122833252\n",
      "Epoch 17, iter 440, loss: 0.8815176486968994\n",
      "Epoch 17, iter 450, loss: 2.5591976642608643\n",
      "Epoch 17, iter 460, loss: 1.7778129577636719\n",
      "Epoch 17, iter 470, loss: 0.6458946466445923\n",
      "Epoch 17, iter 480, loss: 1.6462000608444214\n",
      "Epoch 17, iter 490, loss: 2.0798192024230957\n",
      "Epoch 17, iter 500, loss: 3.43649959564209\n",
      "Epoch 17, iter 510, loss: 0.9585446119308472\n",
      "Epoch 17, iter 520, loss: 1.22813880443573\n",
      "Epoch 17, iter 530, loss: 2.1106154918670654\n",
      "Epoch 17, iter 540, loss: 1.0000722408294678\n",
      "Epoch 17, iter 550, loss: 0.6115908026695251\n",
      "Epoch 17, iter 560, loss: 0.8807270526885986\n",
      "Epoch 17, iter 570, loss: 0.5318337678909302\n",
      "Epoch 17, iter 580, loss: 0.7568591237068176\n",
      "Epoch 17, iter 590, loss: 0.9218841791152954\n",
      "Epoch 17, iter 600, loss: 7.258245944976807\n",
      "Epoch 17, iter 610, loss: 3.9948487281799316\n",
      "Epoch 17, iter 620, loss: 0.8003260493278503\n",
      "Epoch 17, iter 630, loss: 5.644704818725586\n",
      "Epoch 17, iter 640, loss: 1.9110606908798218\n",
      "Epoch 17, iter 650, loss: 2.2663159370422363\n",
      "Epoch 17, iter 660, loss: 3.270725965499878\n",
      "Epoch 17, iter 670, loss: 6.95669412612915\n",
      "Epoch 17, iter 680, loss: 1.0229355096817017\n",
      "Epoch 17, iter 690, loss: 1.4143632650375366\n",
      "Epoch 17, iter 700, loss: 1.760530948638916\n",
      "Epoch 17, iter 710, loss: 0.6332091093063354\n",
      "Epoch 17, iter 720, loss: 1.112331748008728\n",
      "Epoch 17, iter 730, loss: 1.1132538318634033\n",
      "Epoch 17, iter 740, loss: 0.4253478944301605\n",
      "Epoch 17, iter 750, loss: 0.939609706401825\n",
      "Epoch 17, iter 760, loss: 1.1703829765319824\n",
      "Epoch 17, iter 770, loss: 0.5299937725067139\n",
      "Epoch 17, iter 780, loss: 1.7928822040557861\n",
      "Epoch 17, iter 790, loss: 0.5302858352661133\n",
      "Epoch 17, iter 800, loss: 0.70686274766922\n",
      "Epoch 17, iter 810, loss: 4.518126487731934\n",
      "Epoch 17, iter 820, loss: 1.8171180486679077\n",
      "Model saved after epoch 18\n",
      "Epoch 18, iter 0, loss: 1.194504976272583\n",
      "Epoch 18, iter 10, loss: 5.304017066955566\n",
      "Epoch 18, iter 20, loss: 1.6155143976211548\n",
      "Epoch 18, iter 30, loss: 1.1625633239746094\n",
      "Epoch 18, iter 40, loss: 2.2461535930633545\n",
      "Epoch 18, iter 50, loss: 0.8980525732040405\n",
      "Epoch 18, iter 60, loss: 0.9818540811538696\n",
      "Epoch 18, iter 70, loss: 1.6722428798675537\n",
      "Epoch 18, iter 80, loss: 1.705674648284912\n",
      "Epoch 18, iter 90, loss: 0.7478330135345459\n",
      "Epoch 18, iter 100, loss: 1.2825998067855835\n",
      "Epoch 18, iter 110, loss: 0.43384435772895813\n",
      "Epoch 18, iter 120, loss: 21.762388229370117\n",
      "Epoch 18, iter 130, loss: 0.35757026076316833\n",
      "Epoch 18, iter 140, loss: 0.8550888299942017\n",
      "Epoch 18, iter 150, loss: 0.6148988008499146\n",
      "Epoch 18, iter 160, loss: 1.772497534751892\n",
      "Epoch 18, iter 170, loss: 2.791426658630371\n",
      "Epoch 18, iter 180, loss: 1.5453696250915527\n",
      "Epoch 18, iter 190, loss: 2.1282589435577393\n",
      "Epoch 18, iter 200, loss: 0.4269114136695862\n",
      "Epoch 18, iter 210, loss: 1.6033979654312134\n",
      "Epoch 18, iter 220, loss: 0.7455102801322937\n",
      "Epoch 18, iter 230, loss: 3.6645455360412598\n",
      "Epoch 18, iter 240, loss: 18.59532928466797\n",
      "Epoch 18, iter 250, loss: 1.2696661949157715\n",
      "Epoch 18, iter 260, loss: 0.8765541911125183\n",
      "Epoch 18, iter 270, loss: 1.5741469860076904\n",
      "Epoch 18, iter 280, loss: 0.7787635922431946\n",
      "Epoch 18, iter 290, loss: 8.112024307250977\n",
      "Epoch 18, iter 300, loss: 1.8704084157943726\n",
      "Epoch 18, iter 310, loss: 1.5923014879226685\n",
      "Epoch 18, iter 320, loss: 1.470883846282959\n",
      "Epoch 18, iter 330, loss: 0.5364964008331299\n",
      "Epoch 18, iter 340, loss: 0.796893835067749\n",
      "Epoch 18, iter 350, loss: 1.0851597785949707\n",
      "Epoch 18, iter 360, loss: 0.6488468647003174\n",
      "Epoch 18, iter 370, loss: 0.5448164343833923\n",
      "Epoch 18, iter 380, loss: 2.558725357055664\n",
      "Epoch 18, iter 390, loss: 60.874290466308594\n",
      "Epoch 18, iter 400, loss: 1.3014466762542725\n",
      "Epoch 18, iter 410, loss: 3.1157419681549072\n",
      "Epoch 18, iter 420, loss: 4.9923882484436035\n",
      "Epoch 18, iter 430, loss: 0.425059050321579\n",
      "Epoch 18, iter 440, loss: 1.16798734664917\n",
      "Epoch 18, iter 450, loss: 0.4383777976036072\n",
      "Epoch 18, iter 460, loss: 2.2851898670196533\n",
      "Epoch 18, iter 470, loss: 1.8052161931991577\n",
      "Epoch 18, iter 480, loss: 1.689965844154358\n",
      "Epoch 18, iter 490, loss: 1.129897952079773\n",
      "Epoch 18, iter 500, loss: 0.6348184943199158\n",
      "Epoch 18, iter 510, loss: 0.4854629933834076\n",
      "Epoch 18, iter 520, loss: 1.0324089527130127\n",
      "Epoch 18, iter 530, loss: 11.705793380737305\n",
      "Epoch 18, iter 540, loss: 3.2076096534729004\n",
      "Epoch 18, iter 550, loss: 2.2246246337890625\n",
      "Epoch 18, iter 560, loss: 3.482107639312744\n",
      "Epoch 18, iter 570, loss: 2.1147797107696533\n",
      "Epoch 18, iter 580, loss: 0.7225454449653625\n",
      "Epoch 18, iter 590, loss: 0.5175106525421143\n",
      "Epoch 18, iter 600, loss: 0.9185664653778076\n",
      "Epoch 18, iter 610, loss: 0.7065608501434326\n",
      "Epoch 18, iter 620, loss: 0.7442287802696228\n",
      "Epoch 18, iter 630, loss: 0.9634950160980225\n",
      "Epoch 18, iter 640, loss: 0.3441319167613983\n",
      "Epoch 18, iter 650, loss: 1.2175320386886597\n",
      "Epoch 18, iter 660, loss: 1.6133114099502563\n",
      "Epoch 18, iter 670, loss: 2.0216193199157715\n",
      "Epoch 18, iter 680, loss: 0.8502058386802673\n",
      "Epoch 18, iter 690, loss: 0.6880398392677307\n",
      "Epoch 18, iter 700, loss: 2.3079442977905273\n",
      "Epoch 18, iter 710, loss: 3.5009093284606934\n",
      "Epoch 18, iter 720, loss: 3.3807313442230225\n",
      "Epoch 18, iter 730, loss: 2.968693733215332\n",
      "Epoch 18, iter 740, loss: 1.9267265796661377\n",
      "Epoch 18, iter 750, loss: 0.7335922122001648\n",
      "Epoch 18, iter 760, loss: 1.1040290594100952\n",
      "Epoch 18, iter 770, loss: 2.1871023178100586\n",
      "Epoch 18, iter 780, loss: 0.9200869798660278\n",
      "Epoch 18, iter 790, loss: 0.4368472397327423\n",
      "Epoch 18, iter 800, loss: 0.9630376696586609\n",
      "Epoch 18, iter 810, loss: 0.30745118856430054\n",
      "Epoch 18, iter 820, loss: 1.2562618255615234\n",
      "Model saved after epoch 19\n",
      "Epoch 19, iter 0, loss: 5.400265693664551\n",
      "Epoch 19, iter 10, loss: 1.215246558189392\n",
      "Epoch 19, iter 20, loss: 0.8059850931167603\n",
      "Epoch 19, iter 30, loss: 2.3845057487487793\n",
      "Epoch 19, iter 40, loss: 0.66703200340271\n",
      "Epoch 19, iter 50, loss: 0.6866545081138611\n",
      "Epoch 19, iter 60, loss: 0.6899373531341553\n",
      "Epoch 19, iter 70, loss: 0.4414898753166199\n",
      "Epoch 19, iter 80, loss: 0.5071997046470642\n",
      "Epoch 19, iter 90, loss: 0.8131778240203857\n",
      "Epoch 19, iter 100, loss: 0.967473566532135\n",
      "Epoch 19, iter 110, loss: 1.157796859741211\n",
      "Epoch 19, iter 120, loss: 0.6350839138031006\n",
      "Epoch 19, iter 130, loss: 1.3676930665969849\n",
      "Epoch 19, iter 140, loss: 0.7152632474899292\n",
      "Epoch 19, iter 150, loss: 0.7519439458847046\n",
      "Epoch 19, iter 160, loss: 2.037663459777832\n",
      "Epoch 19, iter 170, loss: 0.4154617488384247\n",
      "Epoch 19, iter 180, loss: 1.2218281030654907\n",
      "Epoch 19, iter 190, loss: 0.5490751266479492\n",
      "Epoch 19, iter 200, loss: 0.9699757099151611\n",
      "Epoch 19, iter 210, loss: 0.6954051852226257\n",
      "Epoch 19, iter 220, loss: 0.395734041929245\n",
      "Epoch 19, iter 230, loss: 1.8154513835906982\n",
      "Epoch 19, iter 240, loss: 3.186959981918335\n",
      "Epoch 19, iter 250, loss: 3.079399824142456\n",
      "Epoch 19, iter 260, loss: 0.7799407839775085\n",
      "Epoch 19, iter 270, loss: 1.123889684677124\n",
      "Epoch 19, iter 280, loss: 0.8443590402603149\n",
      "Epoch 19, iter 290, loss: 53.97029495239258\n",
      "Epoch 19, iter 300, loss: 41.8758430480957\n",
      "Epoch 19, iter 310, loss: 0.6979486346244812\n",
      "Epoch 19, iter 320, loss: 1.0913522243499756\n",
      "Epoch 19, iter 330, loss: 0.40901216864585876\n",
      "Epoch 19, iter 340, loss: 0.9359606504440308\n",
      "Epoch 19, iter 350, loss: 0.4753141701221466\n",
      "Epoch 19, iter 360, loss: 1.188504695892334\n",
      "Epoch 19, iter 370, loss: 0.6539176106452942\n",
      "Epoch 19, iter 380, loss: 1.61356520652771\n",
      "Epoch 19, iter 390, loss: 0.7772256731987\n",
      "Epoch 19, iter 400, loss: 1.096343755722046\n",
      "Epoch 19, iter 410, loss: 1.8662912845611572\n",
      "Epoch 19, iter 420, loss: 0.8987730741500854\n",
      "Epoch 19, iter 430, loss: 0.3462115526199341\n",
      "Epoch 19, iter 440, loss: 0.46937239170074463\n",
      "Epoch 19, iter 450, loss: 0.9124813675880432\n",
      "Epoch 19, iter 460, loss: 1.6157077550888062\n",
      "Epoch 19, iter 470, loss: 0.6280578970909119\n",
      "Epoch 19, iter 480, loss: 0.45832180976867676\n",
      "Epoch 19, iter 490, loss: 0.9349045753479004\n",
      "Epoch 19, iter 500, loss: 33.7611198425293\n",
      "Epoch 19, iter 510, loss: 1.1836410760879517\n",
      "Epoch 19, iter 520, loss: 0.8706701397895813\n",
      "Epoch 19, iter 530, loss: 3.0369203090667725\n",
      "Epoch 19, iter 540, loss: 2.0141351222991943\n",
      "Epoch 19, iter 550, loss: 4.999639511108398\n",
      "Epoch 19, iter 560, loss: 1.2312595844268799\n",
      "Epoch 19, iter 570, loss: 0.3887738585472107\n",
      "Epoch 19, iter 580, loss: 4.025378227233887\n",
      "Epoch 19, iter 590, loss: 0.6751503348350525\n",
      "Epoch 19, iter 600, loss: 0.650994062423706\n",
      "Epoch 19, iter 610, loss: 0.6323449015617371\n",
      "Epoch 19, iter 620, loss: 1.3668431043624878\n",
      "Epoch 19, iter 630, loss: 0.9958866834640503\n",
      "Epoch 19, iter 640, loss: 0.5723928809165955\n",
      "Epoch 19, iter 650, loss: 3.6666059494018555\n",
      "Epoch 19, iter 660, loss: 0.612130880355835\n",
      "Epoch 19, iter 670, loss: 0.4026501476764679\n",
      "Epoch 19, iter 680, loss: 0.8079151511192322\n",
      "Epoch 19, iter 690, loss: 0.5473307371139526\n",
      "Epoch 19, iter 700, loss: 4.313432693481445\n",
      "Epoch 19, iter 710, loss: 0.9036186337471008\n",
      "Epoch 19, iter 720, loss: 0.2670244872570038\n",
      "Epoch 19, iter 730, loss: 0.6218059659004211\n",
      "Epoch 19, iter 740, loss: 1.0335185527801514\n",
      "Epoch 19, iter 750, loss: 1.2196623086929321\n",
      "Epoch 19, iter 760, loss: 2.119854211807251\n",
      "Epoch 19, iter 770, loss: 1.5361336469650269\n",
      "Epoch 19, iter 780, loss: 0.9078196287155151\n",
      "Epoch 19, iter 790, loss: 0.35344821214675903\n",
      "Epoch 19, iter 800, loss: 0.9483270645141602\n",
      "Epoch 19, iter 810, loss: 0.7415476441383362\n",
      "Epoch 19, iter 820, loss: 0.5149238109588623\n",
      "Model saved after epoch 20\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, kps) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        kps = kps.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, kps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, iter {i}, loss: {loss.item()}\")\n",
    "\n",
    "    torch.save(model.state_dict(), f\"model_epoch_{epoch+1}.pth\")\n",
    "    print(f\"Model saved after epoch {epoch+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annay\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\annay\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\annay\\AppData\\Local\\Temp\\ipykernel_22616\\2217788890.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location='cpu'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model(model_path):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 14*2) \n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def predict_keypoints(model, image, transform):\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_tensor = transform(image_rgb).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "    \n",
    "    keypoints = outputs.squeeze().cpu().numpy()\n",
    "    original_h, original_w = image.shape[:2]\n",
    "    keypoints[::2] *= original_w / 224.0\n",
    "    keypoints[1::2] *= original_h / 224.0\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "def draw_keypoints(image, keypoints):\n",
    "    keypoints = keypoints.astype(int)\n",
    "    \n",
    "    for i in range(0, len(keypoints), 2):\n",
    "        x, y = keypoints[i], keypoints[i + 1]\n",
    "        cv2.circle(image, (x, y), 5, (0, 255, 0), -1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "model_path = \"model_epoch_18.pth\"\n",
    "model = load_model(model_path)\n",
    "transform = get_transform()\n",
    "\n",
    "image = cv2.imread(\"test.jpg\")\n",
    "\n",
    "keypoints = predict_keypoints(model, image, transform)\n",
    "image_with_keypoints = draw_keypoints(image, keypoints)\n",
    "\n",
    "cv2.imwrite('output_with_keypoints181.jpg', image_with_keypoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointsVisualizer:\n",
    "    def __init__(self, keypoint_color=(0, 255, 0), keypoint_radius=5):\n",
    "        self.keypoint_color = keypoint_color\n",
    "        self.keypoint_radius = keypoint_radius\n",
    "\n",
    "    def draw_keypoints(self, frame, keypoints):\n",
    "        for i in range(0, len(keypoints), 2):\n",
    "            x, y = int(keypoints[i]), int(keypoints[i+1])\n",
    "            cv2.circle(frame, (x, y), self.keypoint_radius, self.keypoint_color, -1)\n",
    "        return frame\n",
    "\n",
    "    def draw_keypoints_on_video(self, video_path, model, transform):\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open video.\")\n",
    "            return None\n",
    "\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "        output_path = 'output_with_keypoints_video.mp4'\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            keypoints = predict_keypoints(model, image_rgb, transform)\n",
    "\n",
    "            frame_with_keypoints = self.draw_keypoints(frame, keypoints)\n",
    "\n",
    "            out.write(frame_with_keypoints)\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "        return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annay\\AppData\\Local\\Temp\\ipykernel_22616\\3857978176.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location='cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output video saved at: output_with_keypoints_video.mp4\n"
     ]
    }
   ],
   "source": [
    "model_path = \"model_epoch_18.pth\"\n",
    "model = load_model(model_path)\n",
    "transform = get_transform()\n",
    "\n",
    "visualizer = KeypointsVisualizer()\n",
    "input_video_path = \"input_videos/input_video.mp4\"\n",
    "output_video_path = visualizer.draw_keypoints_on_video(input_video_path, model, transform)\n",
    "\n",
    "print(f\"Output video saved at: {output_video_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
